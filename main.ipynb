{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a92833d",
   "metadata": {},
   "source": [
    "# Project Name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173cb1ee",
   "metadata": {},
   "source": [
    "#### brief description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44c077d",
   "metadata": {},
   "source": [
    "## 1. Background & Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ab87b9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aea270d0",
   "metadata": {},
   "source": [
    "## 2. Set up, Data Collection, EDA, Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed957162",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c215e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derekkuang/cse158_assignment2/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import yfinance as yf\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dd4b692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>register_index</th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>author</th>\n",
       "      <th>datetime</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>score</th>\n",
       "      <th>comments</th>\n",
       "      <th>text</th>\n",
       "      <th>author_post_karma</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14b78hkjoe86nf</td>\n",
       "      <td>14b78hk</td>\n",
       "      <td>joe86nf</td>\n",
       "      <td>scott_jr</td>\n",
       "      <td>2023-06-16 20:36:55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Watch til 1 10</td>\n",
       "      <td>32102.0</td>\n",
       "      <td>Meme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14b71m2post</td>\n",
       "      <td>14b71m2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>merakibret</td>\n",
       "      <td>2023-06-16 20:24:01</td>\n",
       "      <td>I had my first ever big success with options t...</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Entered an Iron Condor on ADBE yesterday at 45...</td>\n",
       "      <td>343.0</td>\n",
       "      <td>Gain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14b71m2joe6du9</td>\n",
       "      <td>14b71m2</td>\n",
       "      <td>joe6du9</td>\n",
       "      <td>VisualMod</td>\n",
       "      <td>2023-06-16 20:24:07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>User Report                            Tota...</td>\n",
       "      <td>725083.0</td>\n",
       "      <td>Gain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14b71m2joe6een</td>\n",
       "      <td>14b71m2</td>\n",
       "      <td>joe6een</td>\n",
       "      <td>VisualMod</td>\n",
       "      <td>2023-06-16 20:24:13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>That was a very wise move</td>\n",
       "      <td>725083.0</td>\n",
       "      <td>Gain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14b71m2joe7yy4</td>\n",
       "      <td>14b71m2</td>\n",
       "      <td>joe7yy4</td>\n",
       "      <td>DreamcatcherEgg</td>\n",
       "      <td>2023-06-16 20:35:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All you have to do is repeat this same winning...</td>\n",
       "      <td>6088.0</td>\n",
       "      <td>Gain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3033535</th>\n",
       "      <td>1j96owemhd8ajs</td>\n",
       "      <td>1j96owe</td>\n",
       "      <td>mhd8ajs</td>\n",
       "      <td>jarail</td>\n",
       "      <td>2025-03-12 11:25:28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hopefully he made the whole story up</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3033536</th>\n",
       "      <td>1j96owemhcapeb</td>\n",
       "      <td>1j96owe</td>\n",
       "      <td>mhcapeb</td>\n",
       "      <td>South_Age974</td>\n",
       "      <td>2025-03-12 05:46:48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>holy f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3033537</th>\n",
       "      <td>1j96owemhjt5np</td>\n",
       "      <td>1j96owe</td>\n",
       "      <td>mhjt5np</td>\n",
       "      <td>PickinLosers</td>\n",
       "      <td>2025-03-13 11:49:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I like to call them PDFs  public domain fries</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3033538</th>\n",
       "      <td>1j96owemhex8ls</td>\n",
       "      <td>1j96owe</td>\n",
       "      <td>mhex8ls</td>\n",
       "      <td>The_Whackest</td>\n",
       "      <td>2025-03-12 17:04:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singsongy  Some make you laugh  and others ma...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3033539</th>\n",
       "      <td>1j96owemhd99uu</td>\n",
       "      <td>1j96owe</td>\n",
       "      <td>mhd99uu</td>\n",
       "      <td>Rosebunse</td>\n",
       "      <td>2025-03-12 11:33:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I guess I m more worried about all the people ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discussion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3033540 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         register_index  post_id comment_id           author  \\\n",
       "0        14b78hkjoe86nf  14b78hk    joe86nf         scott_jr   \n",
       "1           14b71m2post  14b71m2        NaN       merakibret   \n",
       "2        14b71m2joe6du9  14b71m2    joe6du9        VisualMod   \n",
       "3        14b71m2joe6een  14b71m2    joe6een        VisualMod   \n",
       "4        14b71m2joe7yy4  14b71m2    joe7yy4  DreamcatcherEgg   \n",
       "...                 ...      ...        ...              ...   \n",
       "3033535  1j96owemhd8ajs  1j96owe    mhd8ajs           jarail   \n",
       "3033536  1j96owemhcapeb  1j96owe    mhcapeb     South_Age974   \n",
       "3033537  1j96owemhjt5np  1j96owe    mhjt5np     PickinLosers   \n",
       "3033538  1j96owemhex8ls  1j96owe    mhex8ls     The_Whackest   \n",
       "3033539  1j96owemhd99uu  1j96owe    mhd99uu        Rosebunse   \n",
       "\n",
       "                    datetime  \\\n",
       "0        2023-06-16 20:36:55   \n",
       "1        2023-06-16 20:24:01   \n",
       "2        2023-06-16 20:24:07   \n",
       "3        2023-06-16 20:24:13   \n",
       "4        2023-06-16 20:35:23   \n",
       "...                      ...   \n",
       "3033535  2025-03-12 11:25:28   \n",
       "3033536  2025-03-12 05:46:48   \n",
       "3033537  2025-03-13 11:49:05   \n",
       "3033538  2025-03-12 17:04:15   \n",
       "3033539  2025-03-12 11:33:20   \n",
       "\n",
       "                                                     title  \\\n",
       "0                                                      NaN   \n",
       "1        I had my first ever big success with options t...   \n",
       "2                                                      NaN   \n",
       "3                                                      NaN   \n",
       "4                                                      NaN   \n",
       "...                                                    ...   \n",
       "3033535                                                NaN   \n",
       "3033536                                                NaN   \n",
       "3033537                                                NaN   \n",
       "3033538                                                NaN   \n",
       "3033539                                                NaN   \n",
       "\n",
       "                                                       url  score  comments  \\\n",
       "0                                                      NaN    1.0       NaN   \n",
       "1        https://www.reddit.com/r/wallstreetbets/commen...    8.0       6.0   \n",
       "2                                                      NaN    1.0       NaN   \n",
       "3                                                      NaN    2.0       NaN   \n",
       "4                                                      NaN    2.0       NaN   \n",
       "...                                                    ...    ...       ...   \n",
       "3033535                                                NaN    4.0       NaN   \n",
       "3033536                                                NaN    2.0       NaN   \n",
       "3033537                                                NaN    2.0       NaN   \n",
       "3033538                                                NaN    1.0       NaN   \n",
       "3033539                                                NaN    3.0       NaN   \n",
       "\n",
       "                                                      text  author_post_karma  \\\n",
       "0                                           Watch til 1 10            32102.0   \n",
       "1        Entered an Iron Condor on ADBE yesterday at 45...              343.0   \n",
       "2           User Report                            Tota...           725083.0   \n",
       "3                               That was a very wise move            725083.0   \n",
       "4        All you have to do is repeat this same winning...             6088.0   \n",
       "...                                                    ...                ...   \n",
       "3033535              Hopefully he made the whole story up                 NaN   \n",
       "3033536                                          holy f                   NaN   \n",
       "3033537     I like to call them PDFs  public domain fries                 NaN   \n",
       "3033538   Singsongy  Some make you laugh  and others ma...                NaN   \n",
       "3033539  I guess I m more worried about all the people ...                NaN   \n",
       "\n",
       "                tag  \n",
       "0              Meme  \n",
       "1              Gain  \n",
       "2              Gain  \n",
       "3              Gain  \n",
       "4              Gain  \n",
       "...             ...  \n",
       "3033535  Discussion  \n",
       "3033536  Discussion  \n",
       "3033537  Discussion  \n",
       "3033538  Discussion  \n",
       "3033539  Discussion  \n",
       "\n",
       "[3033540 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in main csv\n",
    "wsb = pd.read_csv(\"data/wsb.csv\")\n",
    "wsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ecada74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3033540 entries, 0 to 3033539\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   register_index     object \n",
      " 1   post_id            object \n",
      " 2   comment_id         object \n",
      " 3   author             object \n",
      " 4   datetime           object \n",
      " 5   title              object \n",
      " 6   url                object \n",
      " 7   score              float64\n",
      " 8   comments           float64\n",
      " 9   text               object \n",
      " 10  author_post_karma  float64\n",
      " 11  tag                object \n",
      "dtypes: float64(3), object(9)\n",
      "memory usage: 277.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3033540, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scout dataframe\n",
    "wsb.info()\n",
    "wsb.head()\n",
    "wsb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d914fb6",
   "metadata": {},
   "source": [
    "#### Cleaning the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d78c5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3033540 entries, 0 to 3033539\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Dtype         \n",
      "---  ------             -----         \n",
      " 0   post_id            object        \n",
      " 1   comment_id         object        \n",
      " 2   author             object        \n",
      " 3   datetime           datetime64[ns]\n",
      " 4   title              object        \n",
      " 5   url                object        \n",
      " 6   score              int64         \n",
      " 7   comments           int64         \n",
      " 8   text               object        \n",
      " 9   author_post_karma  int64         \n",
      " 10  tag                category      \n",
      " 11  is_post            bool          \n",
      "dtypes: bool(1), category(1), datetime64[ns](1), int64(3), object(6)\n",
      "memory usage: 237.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3033540, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop uneccessary columns\n",
    "wsb = wsb.drop(columns=[\"register_index\"])\n",
    "\n",
    "# convert datetime column to datetime type and normalize to date only\n",
    "wsb[\"datetime\"] = pd.to_datetime(wsb[\"datetime\"], errors=\"coerce\").dt.normalize()\n",
    "\n",
    "# convert numeric columns to int type and fill na with 0\n",
    "numeric_cols = [\"score\", \"comments\", \"author_post_karma\"]\n",
    "for col in numeric_cols:\n",
    "    wsb[col] = pd.to_numeric(wsb[col], errors=\"coerce\")\n",
    "    wsb[col] = wsb[col].fillna(0).astype(int)\n",
    "\n",
    "# clean and normalize tag column\n",
    "wsb[\"tag\"] = (\n",
    "    wsb[\"tag\"].fillna(\"unknown\").str.strip().str.lower().str.replace(r\"\\s+\", \"_\", regex=True)\n",
    ")\n",
    "wsb[\"tag\"] = wsb[\"tag\"].astype(\"category\")\n",
    "\n",
    "# identify post or comment\n",
    "wsb[\"is_post\"] = wsb[\"comment_id\"].isna()\n",
    "\n",
    "# sanity check\n",
    "wsb.info()\n",
    "wsb.head()\n",
    "wsb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509956b5",
   "metadata": {},
   "source": [
    "#### basic filtering / denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd32b19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2956091, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove obvious bot/moderator authors\n",
    "bot_users = [\"VisualMod\", \"AutoModerator\"]\n",
    "wsb = wsb[~wsb[\"author\"].isin(bot_users)]\n",
    "\n",
    "# drop rows with deleted/empty content\n",
    "garbage_tokens = {\"\", \"[deleted]\", \"[removed]\"}\n",
    "title_clean = wsb[\"title\"].fillna(\"\").str.strip()\n",
    "text_clean = wsb[\"text\"].fillna(\"\").str.strip()\n",
    "\n",
    "title_garbage = title_clean.isin(garbage_tokens)\n",
    "text_garbage = text_clean.isin(garbage_tokens)\n",
    "\n",
    "post_mask = wsb[\"is_post\"]\n",
    "comment_mask = ~wsb[\"is_post\"]\n",
    "\n",
    "drop_mask = (post_mask & title_garbage & text_garbage) | (comment_mask & text_garbage)\n",
    "wsb = wsb[~drop_mask]\n",
    "\n",
    "wsb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8463a264",
   "metadata": {},
   "source": [
    "#### Light intial text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a4f39d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2956091, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build canonical text field for NLP\n",
    "title_component = wsb[\"title\"].fillna(\"\").astype(str)\n",
    "text_component = wsb[\"text\"].fillna(\"\").astype(str)\n",
    "\n",
    "post_raw_text = (title_component + \"\\n\\n\" + text_component).str.strip()\n",
    "comment_raw_text = text_component.str.strip()\n",
    "\n",
    "wsb[\"raw_text\"] = post_raw_text.where(wsb[\"is_post\"], comment_raw_text)\n",
    "wsb = wsb[wsb[\"raw_text\"] != \"\"]\n",
    "\n",
    "# light text normalization for downstream models\n",
    "import re\n",
    "url_pattern = re.compile(r\"http\\S+\")\n",
    "\n",
    "def clean_text_value(s: str) -> str:\n",
    "    s = str(s)\n",
    "    s = url_pattern.sub(\"\", s)\n",
    "    s = s.replace(\"\\n\", \" \")\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s.strip()\n",
    "\n",
    "wsb[\"clean_text\"] = wsb[\"raw_text\"].map(clean_text_value).str.lower()\n",
    "\n",
    "\n",
    "wsb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3946be",
   "metadata": {},
   "source": [
    "#### Save cleaned df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df8a6eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsb.to_csv(\"data/wsb_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7132740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in cleaned csv\n",
    "wsb = pd.read_csv('data/wsb_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45abb93d",
   "metadata": {},
   "source": [
    "#### Extract and Identify Stock Symbol from content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51290625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_tokens</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11132</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>49561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>AI</td>\n",
       "      <td>40492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16203</th>\n",
       "      <td>US</td>\n",
       "      <td>29507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11519</th>\n",
       "      <td>OP</td>\n",
       "      <td>26281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14563</th>\n",
       "      <td>SPY</td>\n",
       "      <td>25820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17298</th>\n",
       "      <td>WSB</td>\n",
       "      <td>19541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15743</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>17708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>AMD</td>\n",
       "      <td>13938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2545</th>\n",
       "      <td>CEO</td>\n",
       "      <td>10445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3621</th>\n",
       "      <td>DD</td>\n",
       "      <td>9184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8005</th>\n",
       "      <td>IV</td>\n",
       "      <td>7983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15289</th>\n",
       "      <td>THE</td>\n",
       "      <td>7384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>BTC</td>\n",
       "      <td>7234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4830</th>\n",
       "      <td>EV</td>\n",
       "      <td>6298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14231</th>\n",
       "      <td>SMCI</td>\n",
       "      <td>5930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12726</th>\n",
       "      <td>QQQ</td>\n",
       "      <td>5655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4776</th>\n",
       "      <td>ETF</td>\n",
       "      <td>5529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>5422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17751</th>\n",
       "      <td>YOLO</td>\n",
       "      <td>5386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9214</th>\n",
       "      <td>LOL</td>\n",
       "      <td>5363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15317</th>\n",
       "      <td>THIS</td>\n",
       "      <td>5228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>ATH</td>\n",
       "      <td>5138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3110</th>\n",
       "      <td>CPI</td>\n",
       "      <td>4935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11638</th>\n",
       "      <td>OTM</td>\n",
       "      <td>4868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10277</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>4839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15756</th>\n",
       "      <td>TSM</td>\n",
       "      <td>4827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9139</th>\n",
       "      <td>LMAO</td>\n",
       "      <td>4401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7906</th>\n",
       "      <td>IS</td>\n",
       "      <td>4335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>AND</td>\n",
       "      <td>4323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7955</th>\n",
       "      <td>IT</td>\n",
       "      <td>4220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      candidate_tokens  count\n",
       "11132             NVDA  49561\n",
       "381                 AI  40492\n",
       "16203               US  29507\n",
       "11519               OP  26281\n",
       "14563              SPY  25820\n",
       "17298              WSB  19541\n",
       "15743             TSLA  17708\n",
       "578                AMD  13938\n",
       "2545               CEO  10445\n",
       "3621                DD   9184\n",
       "8005                IV   7983\n",
       "15289              THE   7384\n",
       "2063               BTC   7234\n",
       "4830                EV   6298\n",
       "14231             SMCI   5930\n",
       "12726              QQQ   5655\n",
       "4776               ETF   5529\n",
       "37                AAPL   5422\n",
       "17751             YOLO   5386\n",
       "9214               LOL   5363\n",
       "15317             THIS   5228\n",
       "1012               ATH   5138\n",
       "3110               CPI   4935\n",
       "11638              OTM   4868\n",
       "10277             MSFT   4839\n",
       "15756              TSM   4827\n",
       "9139              LMAO   4401\n",
       "7906                IS   4335\n",
       "661                AND   4323\n",
       "7955                IT   4220"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple regexes\n",
    "cashtag_pattern = re.compile(r'\\$[A-Za-z]{1,5}')\n",
    "upper_pattern   = re.compile(r'\\b[A-Z]{2,5}\\b')  # 2–5 uppercase letters\n",
    "\n",
    "def extract_candidate_tokens(text):\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "\n",
    "    cands = set()\n",
    "\n",
    "    # $TSLA, $GME\n",
    "    for m in cashtag_pattern.findall(text):\n",
    "        cands.add(m[1:].upper())  # strip '$'\n",
    "\n",
    "    # TSLA, GME, NVDA (bare tickers)\n",
    "    for m in upper_pattern.findall(text):\n",
    "        cands.add(m.upper())\n",
    "\n",
    "    return list(cands)\n",
    "\n",
    "wsb['candidate_tokens'] = wsb['raw_text'].apply(extract_candidate_tokens)\n",
    "\n",
    "tokens_exploded = wsb.explode('candidate_tokens')\n",
    "tokens_exploded = tokens_exploded.dropna(subset=['candidate_tokens'])\n",
    "\n",
    "token_counts = (\n",
    "    tokens_exploded\n",
    "    .groupby('candidate_tokens')\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    "    .sort_values('count', ascending=False)\n",
    ")\n",
    "\n",
    "token_counts.head(30)\n",
    "\n",
    "\n",
    "\n",
    "# Count of stock mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d713b30d",
   "metadata": {},
   "source": [
    "#### Filter valid stock sybmols\n",
    "\n",
    "- cross check with yahoo finance to make sure stock symbol is valid, manually check and drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bbdfda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of freq_candidates (count >= 500): 303\n"
     ]
    }
   ],
   "source": [
    "# 1. Filter candidate tokens (at least mentioned 500 times)\n",
    "\n",
    "min_count = 500 \n",
    "freq_candidates = (\n",
    "    token_counts[token_counts['count'] >= min_count]['candidate_tokens']\n",
    "    .astype(str)\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "print(f\"Number of freq_candidates (count >= {min_count}): {len(freq_candidates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c190dbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking yfinance symbols:   0%|          | 0/303 [00:00<?, ?it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:   0%|          | 1/303 [00:00<01:37,  3.10it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:   1%|          | 2/303 [00:00<00:59,  5.03it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['US']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:   1%|          | 3/303 [00:00<00:57,  5.24it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:   1%|▏         | 4/303 [00:00<00:49,  5.99it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:   2%|▏         | 5/303 [00:00<00:52,  5.67it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['WSB']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:   2%|▏         | 6/303 [00:01<01:02,  4.78it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:   2%|▏         | 7/303 [00:01<00:52,  5.59it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:   3%|▎         | 8/303 [00:01<00:46,  6.33it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['CEO']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:   3%|▎         | 9/303 [00:01<01:16,  3.82it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:   3%|▎         | 10/303 [00:02<01:09,  4.19it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['IV']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:   4%|▎         | 11/303 [00:02<01:04,  4.55it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['THE']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:   4%|▍         | 12/303 [00:02<01:01,  4.76it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:   4%|▍         | 13/303 [00:02<00:52,  5.55it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:   5%|▍         | 14/303 [00:02<00:45,  6.29it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:   5%|▍         | 15/303 [00:02<00:41,  6.88it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:   5%|▌         | 16/303 [00:03<01:00,  4.75it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['ETF']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:   6%|▌         | 17/303 [00:03<00:56,  5.07it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:   6%|▌         | 18/303 [00:03<00:56,  5.04it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:   6%|▋         | 19/303 [00:03<00:49,  5.76it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['LOL']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:   7%|▋         | 20/303 [00:03<00:48,  5.85it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['THIS']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:   7%|▋         | 21/303 [00:03<00:42,  6.58it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['ATH']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:   7%|▋         | 22/303 [00:04<01:33,  3.02it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:   8%|▊         | 23/303 [00:04<01:15,  3.69it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['OTM']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:   8%|▊         | 24/303 [00:04<01:01,  4.53it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:   8%|▊         | 25/303 [00:05<00:59,  4.67it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:   9%|▊         | 26/303 [00:05<00:55,  4.98it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['LMAO']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:   9%|▉         | 27/303 [00:05<00:58,  4.70it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['IS']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:   9%|▉         | 28/303 [00:05<01:06,  4.14it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['AND']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  10%|▉         | 29/303 [00:06<01:06,  4.10it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  10%|▉         | 30/303 [00:06<00:55,  4.89it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  10%|█         | 31/303 [00:06<00:59,  4.58it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  11%|█         | 32/303 [00:06<00:57,  4.72it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  11%|█         | 33/303 [00:06<00:55,  4.90it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  11%|█         | 34/303 [00:06<00:50,  5.36it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  12%|█▏        | 35/303 [00:07<00:52,  5.06it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['NOT']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  12%|█▏        | 36/303 [00:07<00:48,  5.51it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['TO']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  12%|█▏        | 37/303 [00:07<00:42,  6.32it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['RIP']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  13%|█▎        | 39/303 [00:07<00:38,  6.87it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  13%|█▎        | 40/303 [00:07<00:40,  6.56it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['GDP']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  14%|█▎        | 41/303 [00:09<02:21,  1.85it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  14%|█▍        | 42/303 [00:09<02:01,  2.15it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  14%|█▍        | 43/303 [00:09<01:42,  2.54it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['PE']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  15%|█▍        | 44/303 [00:10<01:28,  2.93it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  15%|█▍        | 45/303 [00:10<01:11,  3.59it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  15%|█▌        | 46/303 [00:10<01:04,  4.01it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  16%|█▌        | 47/303 [00:10<00:56,  4.52it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['TSMC']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  16%|█▌        | 48/303 [00:10<00:58,  4.37it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['SEC']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  16%|█▌        | 49/303 [00:11<00:54,  4.62it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  17%|█▋        | 50/303 [00:11<00:52,  4.84it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  17%|█▋        | 51/303 [00:11<00:45,  5.53it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['ER']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  17%|█▋        | 52/303 [00:11<00:42,  5.89it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  17%|█▋        | 53/303 [00:11<00:37,  6.65it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['IN']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  18%|█▊        | 54/303 [00:11<00:33,  7.33it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  18%|█▊        | 55/303 [00:11<00:33,  7.49it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  18%|█▊        | 56/303 [00:12<00:38,  6.41it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  19%|█▉        | 57/303 [00:12<00:36,  6.78it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  19%|█▉        | 58/303 [00:12<00:38,  6.41it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['UTC']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  19%|█▉        | 59/303 [00:12<00:34,  7.07it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  20%|█▉        | 60/303 [00:12<00:39,  6.22it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['COVID']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  20%|██        | 61/303 [00:12<00:46,  5.19it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['GPU']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  20%|██        | 62/303 [00:13<00:41,  5.87it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['OF']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  21%|██        | 63/303 [00:13<00:36,  6.65it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['FOMO']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  21%|██        | 64/303 [00:13<00:33,  7.18it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['AH']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  21%|██▏       | 65/303 [00:13<00:37,  6.37it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  22%|██▏       | 66/303 [00:13<00:34,  6.94it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  22%|██▏       | 67/303 [00:13<00:36,  6.40it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['YTD']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  22%|██▏       | 68/303 [00:14<00:41,  5.69it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  23%|██▎       | 69/303 [00:14<00:43,  5.44it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['SPX']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  23%|██▎       | 70/303 [00:14<00:37,  6.28it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['FSD']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  23%|██▎       | 71/303 [00:14<00:45,  5.12it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  24%|██▍       | 72/303 [00:14<00:40,  5.69it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  24%|██▍       | 73/303 [00:14<00:38,  5.97it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['VIX']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  24%|██▍       | 74/303 [00:15<00:38,  5.92it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  25%|██▍       | 75/303 [00:15<00:35,  6.45it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['IRA']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  25%|██▌       | 76/303 [00:15<00:35,  6.32it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['PUTS']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  25%|██▌       | 77/303 [00:15<00:46,  4.88it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['BS']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  26%|██▌       | 78/303 [00:15<00:41,  5.46it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['FUCK']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  26%|██▌       | 79/303 [00:16<00:50,  4.44it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  26%|██▋       | 80/303 [00:16<00:45,  4.85it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  27%|██▋       | 81/303 [00:16<00:45,  4.84it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  27%|██▋       | 82/303 [00:16<00:43,  5.05it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  27%|██▋       | 83/303 [00:16<00:43,  5.04it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['CNBC']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  28%|██▊       | 84/303 [00:17<00:42,  5.10it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  28%|██▊       | 85/303 [00:17<00:47,  4.58it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['VM']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  28%|██▊       | 86/303 [00:17<00:39,  5.46it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['TLDR']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  29%|██▊       | 87/303 [00:17<00:34,  6.24it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  29%|██▉       | 88/303 [00:17<00:37,  5.81it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['MY']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  30%|██▉       | 90/303 [00:17<00:31,  6.73it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  30%|███       | 91/303 [00:18<00:33,  6.28it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['TA']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  30%|███       | 92/303 [00:18<00:40,  5.27it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  31%|███       | 93/303 [00:18<00:41,  5.00it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['JPOW']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  31%|███       | 94/303 [00:19<00:52,  3.98it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  31%|███▏      | 95/303 [00:19<00:51,  4.02it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  32%|███▏      | 96/303 [00:19<00:51,  3.99it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  32%|███▏      | 97/303 [00:19<00:57,  3.57it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['FED']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  32%|███▏      | 98/303 [00:20<01:00,  3.41it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['CALLS']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  33%|███▎      | 99/303 [00:20<01:04,  3.15it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['NO']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  33%|███▎      | 100/303 [00:20<01:01,  3.30it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  33%|███▎      | 101/303 [00:21<00:52,  3.87it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  34%|███▎      | 102/303 [00:21<00:44,  4.54it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['AT']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  34%|███▍      | 103/303 [00:21<00:51,  3.92it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  34%|███▍      | 104/303 [00:21<00:42,  4.69it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['DCA']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  35%|███▍      | 105/303 [00:21<00:35,  5.57it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  35%|███▍      | 106/303 [00:22<00:43,  4.51it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['WE']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  35%|███▌      | 107/303 [00:22<00:51,  3.83it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  36%|███▌      | 108/303 [00:22<00:45,  4.33it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['FOMC']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  36%|███▌      | 109/303 [00:22<00:54,  3.58it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['THAT']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  36%|███▋      | 110/303 [00:23<00:55,  3.46it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['BUY']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  37%|███▋      | 111/303 [00:23<00:44,  4.31it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  37%|███▋      | 112/303 [00:23<00:37,  5.08it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  37%|███▋      | 113/303 [00:23<00:38,  4.92it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  38%|███▊      | 114/303 [00:23<00:35,  5.39it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  38%|███▊      | 115/303 [00:23<00:31,  5.97it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  38%|███▊      | 116/303 [00:24<00:31,  5.99it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['OK']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  39%|███▊      | 117/303 [00:24<00:27,  6.76it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  39%|███▉      | 118/303 [00:24<00:27,  6.83it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  39%|███▉      | 119/303 [00:24<00:33,  5.43it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  40%|███▉      | 120/303 [00:24<00:31,  5.84it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  40%|███▉      | 121/303 [00:24<00:31,  5.83it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['DWAC']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  40%|████      | 122/303 [00:25<00:43,  4.15it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['ATM']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  41%|████      | 123/303 [00:25<00:47,  3.79it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['ME']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  41%|████      | 124/303 [00:25<00:38,  4.62it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  41%|████▏     | 125/303 [00:25<00:36,  4.90it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['AF']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  42%|████▏     | 126/303 [00:26<00:37,  4.67it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  42%|████▏     | 127/303 [00:26<00:37,  4.71it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['MM']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['IF']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  43%|████▎     | 129/303 [00:26<00:32,  5.33it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['DO']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  43%|████▎     | 130/303 [00:26<00:35,  4.94it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  43%|████▎     | 131/303 [00:27<00:38,  4.44it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  44%|████▎     | 132/303 [00:27<00:35,  4.83it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  44%|████▍     | 133/303 [00:27<00:34,  4.86it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['CLICK']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  44%|████▍     | 134/303 [00:27<00:37,  4.48it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['LEAPS']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  45%|████▍     | 135/303 [00:28<00:39,  4.27it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  45%|████▍     | 136/303 [00:28<00:35,  4.74it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  45%|████▌     | 137/303 [00:28<00:36,  4.55it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  46%|████▌     | 138/303 [00:28<00:33,  4.88it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['EOY']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  46%|████▌     | 139/303 [00:28<00:32,  5.06it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['WILL']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  46%|████▌     | 140/303 [00:29<00:33,  4.80it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  47%|████▋     | 141/303 [00:29<00:35,  4.53it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  47%|████▋     | 142/303 [00:29<00:34,  4.70it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['CCP']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  47%|████▋     | 143/303 [00:29<00:28,  5.58it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  48%|████▊     | 144/303 [00:29<00:30,  5.25it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  48%|████▊     | 145/303 [00:30<00:32,  4.90it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  48%|████▊     | 146/303 [00:30<00:28,  5.59it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['LFG']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  49%|████▊     | 147/303 [00:30<00:33,  4.63it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['BUT']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  49%|████▉     | 148/303 [00:30<00:28,  5.47it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  49%|████▉     | 149/303 [00:30<00:35,  4.30it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['SAVE']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  50%|████▉     | 150/303 [00:31<00:35,  4.34it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['EOW']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  50%|████▉     | 151/303 [00:31<00:29,  5.18it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  50%|█████     | 152/303 [00:31<00:34,  4.36it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  50%|█████     | 153/303 [00:31<00:30,  5.00it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  51%|█████     | 154/303 [00:31<00:30,  4.82it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['LLM']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  51%|█████     | 155/303 [00:32<00:26,  5.50it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['PCE']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  51%|█████▏    | 156/303 [00:32<00:23,  6.30it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  52%|█████▏    | 157/303 [00:32<00:28,  5.04it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['AWS']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  52%|█████▏    | 158/303 [00:32<00:25,  5.76it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['YOUR']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  52%|█████▏    | 159/303 [00:33<00:34,  4.20it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  53%|█████▎    | 160/303 [00:33<00:29,  4.77it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  53%|█████▎    | 161/303 [00:33<00:27,  5.26it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  53%|█████▎    | 162/303 [00:33<00:23,  5.96it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  54%|█████▍    | 163/303 [00:33<00:27,  5.18it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  54%|█████▍    | 164/303 [00:33<00:24,  5.67it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  54%|█████▍    | 165/303 [00:33<00:24,  5.62it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['CUDA']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  55%|█████▍    | 166/303 [00:34<00:23,  5.91it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  55%|█████▌    | 167/303 [00:34<00:20,  6.69it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['QE']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  55%|█████▌    | 168/303 [00:34<00:18,  7.33it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['WHAT']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  56%|█████▌    | 169/303 [00:34<00:25,  5.35it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  56%|█████▌    | 170/303 [00:34<00:22,  5.90it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['GUH']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  56%|█████▋    | 171/303 [00:34<00:20,  6.57it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['ONE']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  57%|█████▋    | 172/303 [00:35<00:27,  4.79it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['IM']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  57%|█████▋    | 173/303 [00:35<00:23,  5.65it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['FDA']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  57%|█████▋    | 174/303 [00:35<00:21,  6.11it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['NEVER']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  58%|█████▊    | 175/303 [00:35<00:25,  4.98it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['JP']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  58%|█████▊    | 176/303 [00:36<00:28,  4.53it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['CPU']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  58%|█████▊    | 177/303 [00:36<00:27,  4.65it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  59%|█████▊    | 178/303 [00:36<00:25,  4.96it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['SELL']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  59%|█████▉    | 179/303 [00:36<00:28,  4.40it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  59%|█████▉    | 180/303 [00:36<00:23,  5.16it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  60%|█████▉    | 181/303 [00:36<00:21,  5.65it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  60%|██████    | 182/303 [00:37<00:25,  4.74it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['HAVE']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  60%|██████    | 183/303 [00:37<00:29,  4.06it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  61%|██████    | 184/303 [00:37<00:27,  4.34it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  61%|██████    | 185/303 [00:37<00:24,  4.84it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  61%|██████▏   | 186/303 [00:38<00:29,  3.91it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  62%|██████▏   | 187/303 [00:38<00:25,  4.56it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['DM']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  62%|██████▏   | 188/303 [00:38<00:25,  4.46it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['DR']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  62%|██████▏   | 189/303 [00:38<00:24,  4.62it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  63%|██████▎   | 190/303 [00:39<00:25,  4.35it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  63%|██████▎   | 191/303 [00:39<00:25,  4.38it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  63%|██████▎   | 192/303 [00:39<00:21,  5.24it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['ONLY']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  64%|██████▎   | 193/303 [00:39<00:29,  3.72it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['NASA']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  64%|██████▍   | 194/303 [00:40<00:27,  3.90it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  64%|██████▍   | 195/303 [00:40<00:23,  4.62it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  65%|██████▍   | 196/303 [00:40<00:25,  4.17it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['TL']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  65%|██████▌   | 197/303 [00:40<00:25,  4.10it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  65%|██████▌   | 198/303 [00:41<00:26,  3.92it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  66%|██████▌   | 199/303 [00:41<00:22,  4.61it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  66%|██████▌   | 200/303 [00:41<00:22,  4.49it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['PUT']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  66%|██████▋   | 201/303 [00:41<00:19,  5.25it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['SPAC']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  67%|██████▋   | 202/303 [00:41<00:21,  4.59it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['DFV']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  67%|██████▋   | 203/303 [00:42<00:21,  4.70it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['GET']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  67%|██████▋   | 204/303 [00:42<00:21,  4.58it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  68%|██████▊   | 205/303 [00:42<00:21,  4.62it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['MONEY']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  68%|██████▊   | 206/303 [00:42<00:21,  4.41it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['BEARS']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  68%|██████▊   | 207/303 [00:43<00:25,  3.81it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['SHIT']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  69%|██████▊   | 208/303 [00:43<00:24,  3.85it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  69%|██████▉   | 209/303 [00:43<00:22,  4.09it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  69%|██████▉   | 210/303 [00:43<00:24,  3.83it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['WITH']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  70%|██████▉   | 211/303 [00:44<00:25,  3.60it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  70%|██████▉   | 212/303 [00:44<00:21,  4.29it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  70%|███████   | 213/303 [00:44<00:17,  5.01it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['DOJ']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  71%|███████   | 214/303 [00:44<00:17,  5.19it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['NYSE']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  71%|███████   | 215/303 [00:44<00:14,  5.89it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['DOWN']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  71%|███████▏  | 216/303 [00:44<00:17,  5.02it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  72%|███████▏  | 217/303 [00:45<00:18,  4.57it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  72%|███████▏  | 218/303 [00:45<00:18,  4.69it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  72%|███████▏  | 219/303 [00:45<00:19,  4.33it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  73%|███████▎  | 220/303 [00:45<00:19,  4.33it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  73%|███████▎  | 221/303 [00:46<00:19,  4.20it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  73%|███████▎  | 222/303 [00:46<00:20,  3.89it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['ITS']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  74%|███████▎  | 223/303 [00:46<00:20,  3.91it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['BIG']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  74%|███████▍  | 224/303 [00:46<00:20,  3.83it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  74%|███████▍  | 225/303 [00:47<00:20,  3.89it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['LA']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  75%|███████▍  | 226/303 [00:47<00:18,  4.20it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  75%|███████▍  | 227/303 [00:47<00:18,  4.13it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['FYI']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['VW']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  76%|███████▌  | 229/303 [00:48<00:18,  3.96it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  76%|███████▌  | 230/303 [00:48<00:16,  4.43it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['RE']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  76%|███████▌  | 231/303 [00:48<00:16,  4.29it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['LMFAO']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  77%|███████▋  | 232/303 [00:48<00:19,  3.68it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['POS']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  77%|███████▋  | 233/303 [00:49<00:15,  4.45it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['THEY']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  77%|███████▋  | 234/303 [00:49<00:17,  3.90it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['ROI']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  78%|███████▊  | 235/303 [00:49<00:19,  3.50it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['WHY']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  78%|███████▊  | 236/303 [00:50<00:18,  3.66it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['FB']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02) (Yahoo error = \"Data doesn\\'t exist for startDate = 1686196800, endDate = 1743566400\")')\n",
      "Checking yfinance symbols:  78%|███████▊  | 237/303 [00:50<00:22,  2.88it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  79%|███████▊  | 238/303 [00:50<00:21,  2.97it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  79%|███████▉  | 239/303 [00:51<00:18,  3.47it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['SBF']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  79%|███████▉  | 240/303 [00:51<00:14,  4.29it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  80%|███████▉  | 241/303 [00:51<00:14,  4.22it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['EST']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['BMW']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  80%|████████  | 243/303 [00:51<00:11,  5.33it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  81%|████████  | 244/303 [00:51<00:10,  5.57it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['TESLA']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  81%|████████  | 245/303 [00:52<00:12,  4.76it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['BRK']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  81%|████████  | 246/303 [00:52<00:10,  5.50it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  82%|████████▏ | 247/303 [00:52<00:11,  4.88it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['ML']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  82%|████████▏ | 248/303 [00:52<00:12,  4.53it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  82%|████████▏ | 249/303 [00:52<00:12,  4.39it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['NY']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  83%|████████▎ | 250/303 [00:53<00:10,  5.21it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  83%|████████▎ | 251/303 [00:53<00:10,  4.79it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  83%|████████▎ | 252/303 [00:53<00:09,  5.10it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['STOP']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  83%|████████▎ | 253/303 [00:53<00:10,  4.86it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  84%|████████▍ | 254/303 [00:54<00:11,  4.23it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['WAS']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  84%|████████▍ | 255/303 [00:54<00:09,  5.01it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['VERY']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  84%|████████▍ | 256/303 [00:54<00:10,  4.55it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['AFTER']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  85%|████████▍ | 257/303 [00:54<00:13,  3.37it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  85%|████████▌ | 258/303 [00:55<00:11,  3.80it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['OMG']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  85%|████████▌ | 259/303 [00:55<00:09,  4.52it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['STILL']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  86%|████████▌ | 260/303 [00:55<00:11,  3.68it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  86%|████████▌ | 261/303 [00:55<00:09,  4.43it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  86%|████████▋ | 262/303 [00:55<00:09,  4.32it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['FTX']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  87%|████████▋ | 263/303 [00:56<00:08,  4.74it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['AGAIN']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  87%|████████▋ | 264/303 [00:56<00:09,  3.95it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['NVDIA']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  87%|████████▋ | 265/303 [00:56<00:12,  3.10it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['HOW']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  88%|████████▊ | 266/303 [00:57<00:10,  3.50it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['OG']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  88%|████████▊ | 267/303 [00:57<00:10,  3.57it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  88%|████████▊ | 268/303 [00:57<00:08,  4.26it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  89%|████████▉ | 269/303 [00:57<00:07,  4.67it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  89%|████████▉ | 270/303 [00:57<00:06,  4.84it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['RIGHT']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  89%|████████▉ | 271/303 [00:58<00:07,  4.24it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  90%|████████▉ | 272/303 [00:58<00:07,  4.28it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['FD']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  90%|█████████ | 274/303 [00:58<00:05,  4.86it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  91%|█████████ | 275/303 [00:58<00:05,  5.02it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['LETS']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  91%|█████████ | 276/303 [00:59<00:06,  4.39it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['LIKE']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  91%|█████████▏| 277/303 [00:59<00:07,  3.59it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  92%|█████████▏| 278/303 [00:59<00:06,  3.83it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  92%|█████████▏| 279/303 [01:00<00:06,  3.90it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  92%|█████████▏| 280/303 [01:00<00:05,  4.23it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  93%|█████████▎| 281/303 [01:00<00:04,  4.42it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  93%|█████████▎| 282/303 [01:00<00:04,  4.75it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  93%|█████████▎| 283/303 [01:00<00:04,  4.48it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  94%|█████████▎| 284/303 [01:01<00:04,  4.45it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  94%|█████████▍| 285/303 [01:01<00:03,  4.62it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['WHO']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  94%|█████████▍| 286/303 [01:01<00:03,  4.87it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['TODAY']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  95%|█████████▍| 287/303 [01:01<00:03,  4.64it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['FAA']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  95%|█████████▌| 288/303 [01:01<00:03,  4.98it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['BERS']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-06-08 -> 2025-04-02)')\n",
      "Checking yfinance symbols:  95%|█████████▌| 289/303 [01:02<00:02,  4.95it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['DONT']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  96%|█████████▌| 290/303 [01:02<00:03,  4.33it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  96%|█████████▌| 291/303 [01:02<00:03,  3.67it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['NEW']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  96%|█████████▋| 292/303 [01:03<00:03,  2.90it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['STOCK']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  97%|█████████▋| 293/303 [01:03<00:03,  2.63it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  97%|█████████▋| 294/303 [01:04<00:02,  3.00it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  97%|█████████▋| 295/303 [01:04<00:02,  3.57it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  98%|█████████▊| 296/303 [01:04<00:01,  4.29it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  98%|█████████▊| 297/303 [01:04<00:01,  4.36it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  98%|█████████▊| 298/303 [01:04<00:01,  4.43it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "\n",
      "1 Failed download:\n",
      "['GOING']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "Checking yfinance symbols:  99%|█████████▊| 299/303 [01:05<00:01,  3.30it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  99%|█████████▉| 300/303 [01:05<00:00,  3.11it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols:  99%|█████████▉| 301/303 [01:05<00:00,  3.43it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols: 100%|█████████▉| 302/303 [01:05<00:00,  4.00it/s]/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/3121181422.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
      "Checking yfinance symbols: 100%|██████████| 303/303 [01:06<00:00,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of symbols with real price data: 161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Build valid_tickers via yfinance (check if symbol has price data)\n",
    "\n",
    "start_date = '2023-06-08'\n",
    "end_date   = '2025-04-02'\n",
    "\n",
    "valid_tickers_all = []\n",
    "\n",
    "for sym in tqdm(freq_candidates, desc=\"Checking yfinance symbols\"):\n",
    "    try:\n",
    "        data = yf.download(sym, start=start_date, end=end_date, progress=False)\n",
    "        if not data.empty:\n",
    "            valid_tickers_all.append(sym)\n",
    "    except Exception:\n",
    "        # Skip symbols that cause errors\n",
    "        continue\n",
    "\n",
    "valid_tickers_all = sorted(set(valid_tickers_all))\n",
    "print(f\"Number of symbols with real price data: {len(valid_tickers_all)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd991eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Take the top 150 valid tickers by WSB frequency\n",
    "vc = (\n",
    "    token_counts[token_counts['candidate_tokens'].isin(valid_tickers_all)]\n",
    "    .copy()\n",
    "    .sort_values('count', ascending=False)\n",
    ")\n",
    "\n",
    "top_150 = vc['candidate_tokens'].head(150).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3690517d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After manual_drop filtering: 78 symbols\n"
     ]
    }
   ],
   "source": [
    "# 4. Remove obviously ambiguous / non-stock symbols\n",
    "\n",
    "manual_drop = {\n",
    "    # Common words / pronouns / fillers\n",
    "    \"IT\", \"AM\", \"ARE\", \"FOR\", \"ALL\", \"GO\", \"NOW\", \"OR\", \"JUST\", \"YOU\",\n",
    "    \"MORE\", \"TIME\", \"LOT\", \"WAY\", \"BACK\", \"DAY\",\n",
    "\n",
    "    # Macro / econ / generic finance\n",
    "    \"US\", \"USA\", \"USD\", \"CPI\", \"PPI\", \"EPS\", \"IRS\",\n",
    "    \"IPO\", \"ITM\", \"PM\", \"EOD\",\n",
    "\n",
    "    # Crypto / FX / non-equity focus\n",
    "    \"BTC\", \"ETH\", \"SOL\", \"DOGE\", \"ADA\", \"XRP\", \"USDT\", \"USDC\",\n",
    "\n",
    "    # Slang / memes / platform lingo\n",
    "    \"YOLO\", \"WTF\", \"IMO\", \"MOON\", \"GL\",\n",
    "\n",
    "    # Generic financial/technical terms (not single equities)\n",
    "    \"IV\", \"ETF\", \"RSI\",\n",
    "\n",
    "    # Regions / places\n",
    "    \"EU\", \"UK\", \"NYC\", \"CA\", \"DC\",\n",
    "\n",
    "    # Ambiguous tickers that are almost always normal words or other concepts\n",
    "    \"AI\", \"OP\", \"DD\", \"EV\", \"LINK\", \"TV\", \"ON\", \"UP\", \"VR\", \"PC\", \"SO\",\n",
    "    \"IP\", \"CC\", \"IQ\", \"OPEN\", \"BE\", \"CAN\", \"MS\", \"OS\", \"PT\", \"PDT\",\n",
    "    \"COST\", \"DEI\", \"OUT\", \"HE\", \"UI\", \"PR\", \"AM\", \"AGI\", \"ICE\",\n",
    "\n",
    "    # Misc abbreviations that are usually not equity tickers in WSB text\n",
    "    \"EPS\", \"CFO\", \"AA\", \"GPT\", \"HERE\", \"LOVE\", \"ANY\", \"EDIT\", \"RH\"\n",
    "}\n",
    "\n",
    "\n",
    "filtered_candidates = [t for t in top_150 if t not in manual_drop]\n",
    "print(f\"After manual_drop filtering: {len(filtered_candidates)} symbols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11b1eabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final ticker universe size: 78\n",
      "Preview final_tickers: ['NVDA', 'SPY', 'TSLA', 'AMD', 'SMCI', 'QQQ', 'AAPL', 'MSFT', 'TSM', 'MSTR', 'AMC', 'PLTR', 'INTC', 'DJT', 'META', 'ASTS', 'ARM', 'AMZN', 'MARA', 'RKLB']\n",
      "Saved final tickers to data/valid_tickers_top.json\n"
     ]
    }
   ],
   "source": [
    "# 5. keep and save the final stock ticker list\n",
    "\n",
    "vc_filtered = vc[vc['candidate_tokens'].isin(filtered_candidates)].copy()\n",
    "vc_filtered = vc_filtered.sort_values('count', ascending=False)\n",
    "\n",
    "final_tickers = vc_filtered['candidate_tokens'].tolist()\n",
    "print(f\"Final ticker universe size: {len(final_tickers)}\")\n",
    "print(\"Preview final_tickers:\", final_tickers[:20])\n",
    "\n",
    "# Save final universe to JSON for verification\n",
    "valid_tickers_path = 'data/valid_tickers_top.json'\n",
    "with open(valid_tickers_path, 'w') as f:\n",
    "    json.dump(final_tickers, f, indent=2)\n",
    "\n",
    "print(f\"Saved final tickers to {valid_tickers_path}\")\n",
    "\n",
    "valid_tickers_set = set(final_tickers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d11de32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploded WSB shape: (237237, 16)\n",
      "      datetime ticker\n",
      "13  2023-06-16    SPY\n",
      "26  2023-06-16     TD\n",
      "30  2023-06-16    IWM\n",
      "32  2023-06-16    SPY\n",
      "44  2023-06-16    CCL\n",
      "\n",
      "Top 20 tickers after final filter:\n",
      "ticker\n",
      "NVDA    49561\n",
      "SPY     25820\n",
      "TSLA    17708\n",
      "AMD     13938\n",
      "SMCI     5930\n",
      "QQQ      5655\n",
      "AAPL     5422\n",
      "MSFT     4839\n",
      "TSM      4827\n",
      "MSTR     4191\n",
      "AMC      4121\n",
      "PLTR     3992\n",
      "INTC     3688\n",
      "DJT      3673\n",
      "META     3479\n",
      "ASTS     3062\n",
      "ARM      2828\n",
      "AMZN     2714\n",
      "MARA     2663\n",
      "RKLB     2320\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 6. Re-extract tickers from WSB text using whitelist, save to a final dataframe with one row per (WSB row, ticker)\n",
    "cashtag_pattern = re.compile(r'\\$[A-Za-z]{1,5}')\n",
    "upper_pattern   = re.compile(r'\\b[A-Z]{2,5}\\b')\n",
    "\n",
    "def extract_tickers(text):\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "\n",
    "    cands = set()\n",
    "\n",
    "    # $TSLA/$GME style\n",
    "    for m in cashtag_pattern.findall(text):\n",
    "        cands.add(m[1:].upper())\n",
    "\n",
    "    # TSLA/GME style (bare)\n",
    "    for m in upper_pattern.findall(text):\n",
    "        cands.add(m.upper())\n",
    "\n",
    "    # keep only in the curated top-100 universe\n",
    "    return [t for t in cands if t in valid_tickers_set]\n",
    "\n",
    "wsb['tickers'] = wsb['raw_text'].apply(extract_tickers)\n",
    "\n",
    "# Keep only rows that mention at least one of our final tickers\n",
    "wsb_with_ticker = wsb[wsb['tickers'].str.len() > 0].copy()\n",
    "\n",
    "# One row per (WSB row, ticker)\n",
    "wsb_exploded = (\n",
    "    wsb_with_ticker\n",
    "    .explode('tickers')\n",
    "    .rename(columns={'tickers': 'ticker'})\n",
    ")\n",
    "\n",
    "print(\"Exploded WSB shape:\", wsb_exploded.shape)\n",
    "print(wsb_exploded[['datetime', 'ticker']].head())\n",
    "\n",
    "# sanity check ticker counts\n",
    "print(\"\\nTop 20 tickers after final filter:\")\n",
    "print(wsb_exploded['ticker'].value_counts().head(20))\n",
    "\n",
    "wsb_exploded.to_csv('data/wsb_exploded.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378a1e52",
   "metadata": {},
   "source": [
    "#### Download Associated Price Data from yahoo finance\n",
    "- Create a df with daily price data with our final stock list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef94972f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# tickers: 78\n",
      "Preview: ['NVDA', 'SPY', 'TSLA', 'AMD', 'SMCI', 'QQQ', 'AAPL', 'MSFT', 'TSM', 'MSTR']\n",
      "Raw shape: (460, 468)\n",
      "Column level names: ['Price', 'Ticker']\n",
      "Price        Adj Close                                               \\\n",
      "Ticker            AAPL  ACHR        AMC         AMD        AMZN ARM   \n",
      "Date                                                                  \n",
      "2023-06-01  177.930145  2.99  45.500000  119.470001  122.769997 NaN   \n",
      "2023-06-02  178.779831  2.96  45.500000  117.860001  124.250000 NaN   \n",
      "2023-06-05  177.426270  3.00  46.299999  117.930000  125.300003 NaN   \n",
      "\n",
      "Price                                                ...    Volume            \\\n",
      "Ticker            ASML  ASTS       AVGO          BA  ...      TLRY       TLT   \n",
      "Date                                                 ...                       \n",
      "2023-06-01  710.749329  5.60  76.217293  207.960007  ...  26101451  21040400   \n",
      "2023-06-02  708.675964  5.62  78.344749  213.320007  ...  21272921  19136500   \n",
      "2023-06-05  706.279968  5.67  77.408859  208.779999  ...  15641418  14433200   \n",
      "\n",
      "Price                                                                  \\\n",
      "Ticker           TQQQ       TSLA       TSM      UPS      VOO      VTI   \n",
      "Date                                                                    \n",
      "2023-06-01  216759200  148029900  14998500  2524800  3563600  2696700   \n",
      "2023-06-02  216505600  164398400  13085100  2752200  7368900  3018700   \n",
      "2023-06-05  206261800  151143100  10568500  2314100  3481200  2249400   \n",
      "\n",
      "Price                          \n",
      "Ticker           WMT      ZIM  \n",
      "Date                           \n",
      "2023-06-01  20239200  4152800  \n",
      "2023-06-02  19178100  4640600  \n",
      "2023-06-05  15553200  2443200  \n",
      "\n",
      "[3 rows x 468 columns]\n",
      "After stack → long shape: (35596, 8)\n",
      "Price   datetime ticker   Adj Close       Close        High         Low  \\\n",
      "0     2023-06-01   AAPL  177.930145  180.089996  180.119995  176.929993   \n",
      "1     2023-06-01   ACHR    2.990000    2.990000    3.033000    2.910000   \n",
      "2     2023-06-01    AMC   45.500000   45.500000   46.599998   44.700001   \n",
      "\n",
      "Price        Open      Volume  \n",
      "0      177.699997  68901800.0  \n",
      "1        2.970000   1408000.0  \n",
      "2       45.099998   1243100.0  \n",
      "Columns after stack: ['datetime', 'ticker', 'Adj Close', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
      "Final LONG price data shape: (35596, 8)\n",
      "Price   datetime ticker   adj_close       close        high         low  \\\n",
      "0     2023-06-01   AAPL  177.930145  180.089996  180.119995  176.929993   \n",
      "1     2023-06-02   AAPL  178.779831  180.949997  181.779999  179.259995   \n",
      "2     2023-06-05   AAPL  177.426270  179.580002  184.949997  178.039993   \n",
      "3     2023-06-06   AAPL  177.060699  179.210007  180.119995  177.429993   \n",
      "4     2023-06-07   AAPL  175.687378  177.820007  181.210007  177.320007   \n",
      "\n",
      "Price        open       volume  \n",
      "0      177.699997   68901800.0  \n",
      "1      181.029999   61996900.0  \n",
      "2      182.630005  121946500.0  \n",
      "3      179.970001   64848400.0  \n",
      "4      178.440002   61944600.0  \n",
      "Final columns: ['datetime', 'ticker', 'adj_close', 'close', 'high', 'low', 'open', 'volume']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_m/g3l0_2ld7859l89b672mt3k40000gn/T/ipykernel_78931/1885167002.py:36: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  .stack(level='Ticker')          # stack over ticker level → ticker becomes index level\n"
     ]
    }
   ],
   "source": [
    "# 1. Load your final ticker universe from JSON\n",
    "tickers_path = 'data/valid_tickers_top.json'\n",
    "\n",
    "with open(tickers_path, 'r') as f:\n",
    "    final_tickers = json.load(f)\n",
    "\n",
    "print(f\"# tickers: {len(final_tickers)}\")\n",
    "print(\"Preview:\", final_tickers[:10])\n",
    "\n",
    "# 2. Define date range\n",
    "start_date = '2023-06-01'\n",
    "end_date   = '2025-04-02'\n",
    "\n",
    "# 3. Single multi-ticker download (WIDE, MultiIndex)\n",
    "raw = yf.download(\n",
    "    final_tickers,\n",
    "    start=start_date,\n",
    "    end=end_date,\n",
    "    auto_adjust=False, \n",
    "    progress=False\n",
    ")\n",
    "\n",
    "# raw is wide with MultiIndex columns: (PriceField, Ticker)\n",
    "print(\"Raw shape:\", raw.shape)\n",
    "print(\"Column level names:\", raw.columns.names)\n",
    "print(raw.head(3))\n",
    "\n",
    "# 4. Reshape to LONG: one row per (date, ticker)\n",
    "# Ensure column levels have names (should already be ['Price', 'Ticker'])\n",
    "if raw.columns.names is None or len(raw.columns.names) != 2:\n",
    "    # yfinance usually sets this, but just in case:\n",
    "    raw.columns.names = ['Price', 'Ticker']\n",
    "\n",
    "prices_long = (\n",
    "    raw\n",
    "    .stack(level='Ticker')          # stack over ticker level → ticker becomes index level\n",
    "    .reset_index()                  # turn index back into columns\n",
    "    .rename(columns={'Date': 'datetime', 'Ticker': 'ticker'})\n",
    ")\n",
    "\n",
    "# Now columns should be: ['datetime','ticker','Open','High','Low','Close','Adj Close','Volume']\n",
    "print(\"After stack → long shape:\", prices_long.shape)\n",
    "print(prices_long.head(3))\n",
    "print(\"Columns after stack:\", prices_long.columns.tolist())\n",
    "\n",
    "# 5. Clean column names & add 'date'\n",
    "prices_long = prices_long.rename(\n",
    "    columns={\n",
    "        'Open': 'open',\n",
    "        'High': 'high',\n",
    "        'Low': 'low',\n",
    "        'Close': 'close',\n",
    "        'Adj Close': 'adj_close',\n",
    "        'Volume': 'volume'\n",
    "    }\n",
    ")\n",
    "\n",
    "prices_long['datetime'] = pd.to_datetime(prices_long['datetime'])\n",
    "\n",
    "# Sort for sanity\n",
    "prices_long = prices_long.sort_values(['ticker', 'datetime']).reset_index(drop=True)\n",
    "\n",
    "print(\"Final LONG price data shape:\", prices_long.shape)\n",
    "print(prices_long.head(5))\n",
    "print(\"Final columns:\", prices_long.columns.tolist())\n",
    "\n",
    "out_path = 'data/prices_daily.csv'\n",
    "prices_long.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ba5893",
   "metadata": {},
   "source": [
    "## 3. Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574c2a42",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffc2f47",
   "metadata": {},
   "source": [
    "- Price side feature: return, next day label, big move label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e25aeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price   datetime ticker       close       volume    return  next_return  \\\n",
      "0     2023-06-01   AAPL  180.089996   68901800.0       NaN     0.004775   \n",
      "1     2023-06-02   AAPL  180.949997   61996900.0  0.004775    -0.007571   \n",
      "2     2023-06-05   AAPL  179.580002  121946500.0 -0.007571    -0.002060   \n",
      "3     2023-06-06   AAPL  179.210007   64848400.0 -0.002060    -0.007756   \n",
      "4     2023-06-07   AAPL  177.820007   61944600.0 -0.007756     0.015465   \n",
      "\n",
      "Price  big_move  \n",
      "0             0  \n",
      "1             0  \n",
      "2             0  \n",
      "3             0  \n",
      "4             0  \n"
     ]
    }
   ],
   "source": [
    "# 0. Normalize datetime to day-level but KEEP column name 'datetime'\n",
    "prices_long['datetime'] = pd.to_datetime(prices_long['datetime']).dt.normalize()\n",
    "wsb_exploded['datetime'] = pd.to_datetime(wsb_exploded['datetime']).dt.normalize()\n",
    "\n",
    "# 1. PRICE-SIDE FEATURES: returns + next-day label\n",
    "prices_feat = prices_long.sort_values(['ticker', 'datetime']).copy()\n",
    "\n",
    "# Daily return\n",
    "prices_feat['return'] = prices_feat.groupby('ticker')['close'].pct_change()\n",
    "\n",
    "# Next-day close and next-day return (per ticker)\n",
    "prices_feat['next_close'] = prices_feat.groupby('ticker')['close'].shift(-1)\n",
    "prices_feat['next_return'] = (\n",
    "    (prices_feat['next_close'] - prices_feat['close']) / prices_feat['close']\n",
    ")\n",
    "\n",
    "# Big-move label\n",
    "BIG_MOVE_THRESH = 0.05  # 5% threshold; adjust if you want\n",
    "prices_feat['big_move'] = (\n",
    "    prices_feat['next_return'].abs() >= BIG_MOVE_THRESH\n",
    ").astype(int)\n",
    "\n",
    "# Drop rows with no next-day info\n",
    "prices_feat = prices_feat.dropna(subset=['next_return'])\n",
    "\n",
    "price_cols = [\n",
    "    'datetime', \n",
    "    'ticker',\n",
    "    'close',\n",
    "    'volume',\n",
    "    'return',\n",
    "    'next_return',\n",
    "    'big_move'\n",
    "]\n",
    "prices_feat = prices_feat[price_cols]\n",
    "\n",
    "print(prices_feat.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9912d13c",
   "metadata": {},
   "source": [
    "- WallStreetBet numeric feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b5eeb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WSB numeric daily feature shape: (23612, 7)\n",
      "    datetime ticker  mention_count  score_sum  score_mean  post_fraction  \\\n",
      "0 2023-06-08   AMZN              1          7    7.000000       0.000000   \n",
      "1 2023-06-08   BABA              1          6    6.000000       0.000000   \n",
      "2 2023-06-08    BYD              1          1    1.000000       0.000000   \n",
      "3 2023-06-08    CCL              1         11   11.000000       1.000000   \n",
      "4 2023-06-08   CVNA             15        455   30.333333       0.133333   \n",
      "\n",
      "   unique_authors  \n",
      "0               1  \n",
      "1               1  \n",
      "2               1  \n",
      "3               1  \n",
      "4              10  \n"
     ]
    }
   ],
   "source": [
    "# 2. WSB-SIDE NUMERIC FEATURES per (datetime, ticker)\n",
    "wsb_num = wsb_exploded.copy()\n",
    "\n",
    "# is_post: posts have NaN comment_id, comments have non-null\n",
    "if 'is_post' not in wsb_num.columns:\n",
    "    wsb_num['is_post'] = wsb_num['comment_id'].isna()\n",
    "\n",
    "# score numeric\n",
    "wsb_num['score'] = pd.to_numeric(wsb_num['score'], errors='coerce')\n",
    "\n",
    "group_cols = ['datetime', 'ticker']\n",
    "\n",
    "agg_dict = {\n",
    "    'score': ['count', 'sum', 'mean'],\n",
    "    'is_post': 'mean',\n",
    "    'author': pd.Series.nunique,\n",
    "}\n",
    "\n",
    "wsb_daily = (\n",
    "    wsb_num\n",
    "    .groupby(group_cols)\n",
    "    .agg(agg_dict)\n",
    ")\n",
    "\n",
    "# Flatten columns\n",
    "wsb_daily.columns = [\n",
    "    '_'.join([c for c in col if c]) for col in wsb_daily.columns.ravel()\n",
    "]\n",
    "wsb_daily = wsb_daily.reset_index()\n",
    "\n",
    "wsb_daily = wsb_daily.rename(columns={\n",
    "    'score_count': 'mention_count',\n",
    "    'score_sum': 'score_sum',\n",
    "    'score_mean': 'score_mean',\n",
    "    'is_post_mean': 'post_fraction',\n",
    "    'author_nunique': 'unique_authors'\n",
    "})\n",
    "\n",
    "print(\"WSB numeric daily feature shape:\", wsb_daily.shape)\n",
    "print(wsb_daily.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dc19d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price feature shape: (38577, 7)\n",
      "Price   datetime ticker       close       volume    return  next_return  \\\n",
      "0     2023-06-01   AAPL  180.089996   68901800.0       NaN     0.004775   \n",
      "1     2023-06-02   AAPL  180.949997   61996900.0  0.004775    -0.007571   \n",
      "2     2023-06-05   AAPL  179.580002  121946500.0 -0.007571    -0.002060   \n",
      "3     2023-06-06   AAPL  179.210007   64848400.0 -0.002060    -0.007756   \n",
      "4     2023-06-07   AAPL  177.820007   61944600.0 -0.007756     0.015465   \n",
      "\n",
      "Price  big_move  \n",
      "0             0  \n",
      "1             0  \n",
      "2             0  \n",
      "3             0  \n",
      "4             0  \n",
      "WSB numeric daily feature shape: (25176, 7)\n",
      "    datetime ticker  mention_count  score_sum  score_mean  post_fraction  \\\n",
      "0 2023-06-08   ADBE              2         24        12.0            0.5   \n",
      "1 2023-06-08   AMZN              1          7         7.0            0.0   \n",
      "2 2023-06-08     AR              1         44        44.0            1.0   \n",
      "3 2023-06-08   BABA              1          6         6.0            0.0   \n",
      "4 2023-06-08    BYD              1          1         1.0            0.0   \n",
      "\n",
      "   unique_authors  \n",
      "0               2  \n",
      "1               1  \n",
      "2               1  \n",
      "3               1  \n",
      "4               1  \n",
      "WSB text daily shape: (25176, 3)\n",
      "    datetime ticker                                           doc_text\n",
      "0 2023-06-08   ADBE  adbe earnings play? firefly generative ai x200...\n",
      "1 2023-06-08   AMZN  drilling when i m about go go long amzn googl ...\n",
      "2 2023-06-08     AR  apple vision pro vr/ar headset is the same pri...\n",
      "3 2023-06-08   BABA            do i have to be asian to buy baba calls\n",
      "4 2023-06-08    BYD  no one has ever been able to achieve a monopol...\n",
      "Model DF shape: (17744, 13)\n",
      "    datetime ticker       close      volume    return  next_return  big_move  \\\n",
      "0 2023-06-09   AAPL  180.960007  48900000.0  0.002160     0.015639         0   \n",
      "1 2023-06-12   AAPL  183.789993  54274900.0  0.015639    -0.002612         0   \n",
      "2 2023-06-13   AAPL  183.309998  54929100.0 -0.002612     0.003491         0   \n",
      "3 2023-06-14   AAPL  183.949997  57462900.0  0.003491     0.011199         0   \n",
      "4 2023-06-15   AAPL  186.009995  65433200.0  0.011199    -0.005860         0   \n",
      "\n",
      "   mention_count  score_sum  score_mean  post_fraction  unique_authors  \\\n",
      "0              7         32    4.571429       0.142857               7   \n",
      "1             18        182   10.111111       0.055556              17   \n",
      "2             13        215   16.538462       0.076923              13   \n",
      "3              6         48    8.000000       0.000000               6   \n",
      "4              8         82   10.250000       0.000000               8   \n",
      "\n",
      "                                            doc_text  \n",
      "0  volume tickers in play trading thesis tracking...  \n",
      "1  u restrav just buy aapl and just keep holding ...  \n",
      "2  apple downgrade pushes bullish analyst ratings...  \n",
      "3  trust is my strategy has been trading low risk...  \n",
      "4  ridiculous tech valuations honeywell trades at...  \n",
      "Big-move base rate: 0.11023444544634806\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 2. WSB-SIDE NUMERIC FEATURES per (datetime, ticker)\n",
    "wsb_num = wsb_exploded.copy()\n",
    "\n",
    "# is_post: posts have NaN comment_id, comments have non-null\n",
    "if 'is_post' not in wsb_num.columns:\n",
    "    wsb_num['is_post'] = wsb_num['comment_id'].isna()\n",
    "\n",
    "# score numeric\n",
    "wsb_num['score'] = pd.to_numeric(wsb_num['score'], errors='coerce')\n",
    "\n",
    "group_cols = ['datetime', 'ticker']\n",
    "\n",
    "agg_dict = {\n",
    "    'score': ['count', 'sum', 'mean'],\n",
    "    'is_post': 'mean',\n",
    "    'author': pd.Series.nunique,\n",
    "}\n",
    "\n",
    "wsb_daily = (\n",
    "    wsb_num\n",
    "    .groupby(group_cols)\n",
    "    .agg(agg_dict)\n",
    ")\n",
    "\n",
    "# Flatten columns\n",
    "wsb_daily.columns = [\n",
    "    '_'.join([c for c in col if c]) for col in wsb_daily.columns.ravel()\n",
    "]\n",
    "wsb_daily = wsb_daily.reset_index()\n",
    "\n",
    "wsb_daily = wsb_daily.rename(columns={\n",
    "    'score_count': 'mention_count',\n",
    "    'score_sum': 'score_sum',\n",
    "    'score_mean': 'score_mean',\n",
    "    'is_post_mean': 'post_fraction',\n",
    "    'author_nunique': 'unique_authors'\n",
    "})\n",
    "\n",
    "print(\"WSB numeric daily feature shape:\", wsb_daily.shape)\n",
    "print(wsb_daily.head())\n",
    "\n",
    "# ===================================================\n",
    "# 3. WSB TEXT FEATURES: doc_text per (datetime, ticker)\n",
    "# ===================================================\n",
    "wsb_text = wsb_exploded.copy()\n",
    "\n",
    "# Find the text column\n",
    "TEXT_COL_CANDIDATES = ['clean_text', 'text', 'raw_text']\n",
    "for c in TEXT_COL_CANDIDATES:\n",
    "    if c in wsb_text.columns:\n",
    "        text_col = c\n",
    "        break\n",
    "else:\n",
    "    raise ValueError(\"No text column found in wsb_exploded (expected one of: clean_text, text, raw_text)\")\n",
    "\n",
    "# Ensure string\n",
    "wsb_text[text_col] = wsb_text[text_col].fillna('').astype(str)\n",
    "\n",
    "wsb_text_daily = (\n",
    "    wsb_text\n",
    "    .groupby(['datetime', 'ticker'])[text_col]\n",
    "    .apply(lambda s: ' '.join(s))\n",
    "    .reset_index()\n",
    "    .rename(columns={text_col: 'doc_text'})\n",
    ")\n",
    "\n",
    "print(\"WSB text daily shape:\", wsb_text_daily.shape)\n",
    "print(wsb_text_daily.head())\n",
    "\n",
    "# ===================================================\n",
    "# 4. MERGE: prices + WSB numeric + WSB text\n",
    "# ===================================================\n",
    "model_df = (\n",
    "    prices_feat\n",
    "    .merge(wsb_daily, on=['datetime', 'ticker'], how='inner')\n",
    "    .merge(wsb_text_daily, on=['datetime', 'ticker'], how='inner')\n",
    ")\n",
    "\n",
    "print(\"Model DF shape:\", model_df.shape)\n",
    "print(model_df.head())\n",
    "print(\"Big-move base rate:\", model_df['big_move'].mean())\n",
    "\n",
    "\n",
    "out_path = 'data/modeling_df.csv'\n",
    "model_df.to_csv(out_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cc9189",
   "metadata": {},
   "source": [
    "## 3. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b59389b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline models finally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0f146792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model df after cleaning: (17740, 14)\n",
      "Train dates: 2023-06-08 00:00:00 → 2024-07-08 00:00:00  (259 days)\n",
      "Val dates:   2024-07-09 00:00:00 → 2024-11-27 00:00:00      (55 days)\n",
      "Test dates:  2024-11-29 00:00:00 → 2025-03-31 00:00:00     (56 days)\n",
      "Split sizes: 12395 train / 2750 val / 2595 test\n",
      "\n",
      "================================================================================\n",
      "Baseline 0: Always predict NO BIG MOVE\n",
      "================================================================================\n",
      "TEST:\n",
      "  Accuracy : 0.8566\n",
      "  F1       : 0.0000\n",
      "  Precision: 0.0000\n",
      "  Recall   : 0.0000\n",
      "  (AUC for this is undefined / trivial; model outputs constant score)\n",
      "\n",
      "================================================================================\n",
      "Baseline: Logistic (price-only)\n",
      "================================================================================\n",
      "\n",
      "Validation performance:\n",
      "VAL:\n",
      "  Accuracy : 0.5727\n",
      "  F1       : 0.2098\n",
      "  Precision: 0.1360\n",
      "  Recall   : 0.4588\n",
      "  AUC      : 0.5521\n",
      "\n",
      "Test performance:\n",
      "TEST:\n",
      "  Accuracy : 0.5326\n",
      "  F1       : 0.2617\n",
      "  Precision: 0.1692\n",
      "  Recall   : 0.5780\n",
      "  AUC      : 0.5983\n",
      "\n",
      "================================================================================\n",
      "Baseline: Logistic (WSB-only numeric)\n",
      "================================================================================\n",
      "\n",
      "Validation performance:\n",
      "VAL:\n",
      "  Accuracy : 0.7160\n",
      "  F1       : 0.2006\n",
      "  Precision: 0.1538\n",
      "  Recall   : 0.2882\n",
      "  AUC      : 0.5321\n",
      "\n",
      "Test performance:\n",
      "TEST:\n",
      "  Accuracy : 0.7329\n",
      "  F1       : 0.2410\n",
      "  Precision: 0.2033\n",
      "  Recall   : 0.2957\n",
      "  AUC      : 0.5822\n",
      "\n",
      "================================================================================\n",
      "Baseline: Logistic (price + WSB numeric)\n",
      "================================================================================\n",
      "\n",
      "Validation performance:\n",
      "VAL:\n",
      "  Accuracy : 0.6280\n",
      "  F1       : 0.2221\n",
      "  Precision: 0.1497\n",
      "  Recall   : 0.4294\n",
      "  AUC      : 0.5547\n",
      "\n",
      "Test performance:\n",
      "TEST:\n",
      "  Accuracy : 0.6104\n",
      "  F1       : 0.2647\n",
      "  Precision: 0.1815\n",
      "  Recall   : 0.4892\n",
      "  AUC      : 0.6097\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# 0. Inspect / lightly clean model_df\n",
    "#    Assumes model_df is already in memory\n",
    "#    Columns used: datetime, ticker, big_move, return, volume,\n",
    "#    mention_count, score_sum, score_mean, post_fraction, unique_authors\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# Ensure datetime is datetime64\n",
    "model_df['datetime'] = pd.to_datetime(model_df['datetime'])\n",
    "\n",
    "# Log-transform volume to reduce skew, keep both if you want\n",
    "model_df['log_volume'] = np.log1p(model_df['volume'])\n",
    "\n",
    "# Fill NaNs in WSB features with 0 (no activity)\n",
    "wsb_cols = ['mention_count', 'score_sum', 'score_mean', 'post_fraction', 'unique_authors']\n",
    "for c in wsb_cols:\n",
    "    if c in model_df.columns:\n",
    "        model_df[c] = model_df[c].fillna(0)\n",
    "\n",
    "# Drop any rows missing the core numeric features or label\n",
    "core_numeric = ['return', 'log_volume'] + wsb_cols\n",
    "model_df = model_df.dropna(subset=core_numeric + ['big_move'])\n",
    "\n",
    "print(\"Model df after cleaning:\", model_df.shape)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1. Time-based train/val/test split\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def time_split(df, train_frac=0.7, val_frac=0.15):\n",
    "    \"\"\"\n",
    "    Split by datetime (chronological). No shuffling.\n",
    "    Returns train_df, val_df, test_df.\n",
    "    \"\"\"\n",
    "    df = df.sort_values('datetime')\n",
    "    unique_times = df['datetime'].unique()\n",
    "    n = len(unique_times)\n",
    "    \n",
    "    train_cut = int(n * train_frac)\n",
    "    val_cut   = int(n * (train_frac + val_frac))\n",
    "    \n",
    "    train_times = unique_times[:train_cut]\n",
    "    val_times   = unique_times[train_cut:val_cut]\n",
    "    test_times  = unique_times[val_cut:]\n",
    "    \n",
    "    train_df = df[df['datetime'].isin(train_times)].copy()\n",
    "    val_df   = df[df['datetime'].isin(val_times)].copy()\n",
    "    test_df  = df[df['datetime'].isin(test_times)].copy()\n",
    "    \n",
    "    print(f\"Train dates: {train_times[0]} → {train_times[-1]}  ({len(train_times)} days)\")\n",
    "    print(f\"Val dates:   {val_times[0]} → {val_times[-1]}      ({len(val_times)} days)\")\n",
    "    print(f\"Test dates:  {test_times[0]} → {test_times[-1]}     ({len(test_times)} days)\")\n",
    "    \n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "train_df, val_df, test_df = time_split(model_df)\n",
    "\n",
    "print(\"Split sizes:\",\n",
    "      len(train_df), \"train /\",\n",
    "      len(val_df), \"val /\",\n",
    "      len(test_df), \"test\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2. Helper: train + eval a logistic baseline on given feature list\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def run_logistic_baseline(feature_cols, train_df, val_df, test_df, desc=\"\"):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Baseline: {desc}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    X_train = train_df[feature_cols].values\n",
    "    y_train = train_df['big_move'].values.astype(int)\n",
    "    \n",
    "    X_val   = val_df[feature_cols].values\n",
    "    y_val   = val_df['big_move'].values.astype(int)\n",
    "    \n",
    "    X_test  = test_df[feature_cols].values\n",
    "    y_test  = test_df['big_move'].values.astype(int)\n",
    "    \n",
    "    # Pipeline: scale numeric features, then logistic regression\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', LogisticRegression(\n",
    "            penalty='l2',\n",
    "            C=1.0,\n",
    "            class_weight='balanced',  # helps with class imbalance\n",
    "            max_iter=1000,\n",
    "            solver='lbfgs'\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    # Validation metrics\n",
    "    val_probs = pipe.predict_proba(X_val)[:, 1]\n",
    "    val_pred  = (val_probs >= 0.5).astype(int)\n",
    "    \n",
    "    def report_split(name, y_true, y_pred, y_prob):\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        f1  = f1_score(y_true, y_pred, zero_division=0)\n",
    "        prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "        rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "        try:\n",
    "            auc = roc_auc_score(y_true, y_prob)\n",
    "        except ValueError:\n",
    "            auc = np.nan\n",
    "        \n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  Accuracy : {acc:.4f}\")\n",
    "        print(f\"  F1       : {f1:.4f}\")\n",
    "        print(f\"  Precision: {prec:.4f}\")\n",
    "        print(f\"  Recall   : {rec:.4f}\")\n",
    "        print(f\"  AUC      : {auc:.4f}\")\n",
    "    \n",
    "    print(\"\\nValidation performance:\")\n",
    "    report_split(\"VAL\", y_val, val_pred, val_probs)\n",
    "    \n",
    "    # Test metrics (final)\n",
    "    test_probs = pipe.predict_proba(X_test)[:, 1]\n",
    "    test_pred  = (test_probs >= 0.5).astype(int)\n",
    "    \n",
    "    print(\"\\nTest performance:\")\n",
    "    report_split(\"TEST\", y_test, test_pred, test_probs)\n",
    "    \n",
    "    return pipe\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3. Baseline 0: dumb majority classifier (always 0)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Baseline 0: Always predict NO BIG MOVE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "y_test = test_df['big_move'].values.astype(int)\n",
    "y_pred0 = np.zeros_like(y_test)\n",
    "\n",
    "acc0 = accuracy_score(y_test, y_pred0)\n",
    "f1_0 = f1_score(y_test, y_pred0, zero_division=0)\n",
    "prec0 = precision_score(y_test, y_pred0, zero_division=0)\n",
    "rec0 = recall_score(y_test, y_pred0, zero_division=0)\n",
    "\n",
    "print(f\"TEST:\")\n",
    "print(f\"  Accuracy : {acc0:.4f}\")\n",
    "print(f\"  F1       : {f1_0:.4f}\")\n",
    "print(f\"  Precision: {prec0:.4f}\")\n",
    "print(f\"  Recall   : {rec0:.4f}\")\n",
    "print(\"  (AUC for this is undefined / trivial; model outputs constant score)\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4. Baseline 1: price-only logistic\n",
    "# ---------------------------------------------------\n",
    "\n",
    "price_features = ['return', 'log_volume']\n",
    "pipe_price = run_logistic_baseline(\n",
    "    feature_cols=price_features,\n",
    "    train_df=train_df,\n",
    "    val_df=val_df,\n",
    "    test_df=test_df,\n",
    "    desc=\"Logistic (price-only)\"\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 5. Baseline 2: WSB-metadata-only logistic\n",
    "# ---------------------------------------------------\n",
    "\n",
    "wsb_features = ['mention_count', 'score_sum', 'score_mean', 'post_fraction', 'unique_authors']\n",
    "pipe_wsb = run_logistic_baseline(\n",
    "    feature_cols=wsb_features,\n",
    "    train_df=train_df,\n",
    "    val_df=val_df,\n",
    "    test_df=test_df,\n",
    "    desc=\"Logistic (WSB-only numeric)\"\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 6. Baseline 3: price + WSB numeric logistic\n",
    "# ---------------------------------------------------\n",
    "\n",
    "combined_features = price_features + wsb_features\n",
    "pipe_combined = run_logistic_baseline(\n",
    "    feature_cols=combined_features,\n",
    "    train_df=train_df,\n",
    "    val_df=val_df,\n",
    "    test_df=test_df,\n",
    "    desc=\"Logistic (price + WSB numeric)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8f59c56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF–IDF shapes: (12395, 10000) (2750, 10000) (2595, 10000)\n",
      "\n",
      "======================\n",
      "TEXT-ONLY LOGISTIC\n",
      "======================\n",
      "\n",
      "Validation performance:\n",
      "VAL (text-only):\n",
      "  Accuracy : 0.7731\n",
      "  F1       : 0.3633\n",
      "  Precision: 0.2781\n",
      "  Recall   : 0.5235\n",
      "  AUC      : 0.7589\n",
      "\n",
      "Test performance:\n",
      "TEST (text-only):\n",
      "  Accuracy : 0.7418\n",
      "  F1       : 0.4029\n",
      "  Precision: 0.3013\n",
      "  Recall   : 0.6075\n",
      "  AUC      : 0.7756\n",
      "\n",
      "Combined feature shapes: (12395, 10007) (2750, 10007) (2595, 10007)\n",
      "\n",
      "======================\n",
      "TEXT + NUMERIC LOGISTIC\n",
      "======================\n",
      "\n",
      "Validation performance:\n",
      "VAL (text+num):\n",
      "  Accuracy : 0.7822\n",
      "  F1       : 0.3621\n",
      "  Precision: 0.2838\n",
      "  Recall   : 0.5000\n",
      "  AUC      : 0.7602\n",
      "\n",
      "Test performance:\n",
      "TEST (text+num):\n",
      "  Accuracy : 0.7499\n",
      "  F1       : 0.4158\n",
      "  Precision: 0.3126\n",
      "  Recall   : 0.6210\n",
      "  AUC      : 0.7856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# 0. Check we have the splits and doc_text\n",
    "# ---------------------------------------------------\n",
    "for df_name, df in [('train_df', train_df), ('val_df', val_df), ('test_df', test_df)]:\n",
    "    if 'doc_text' not in df.columns:\n",
    "        raise ValueError(f\"{df_name} is missing 'doc_text' column\")\n",
    "\n",
    "# Make sure text is string\n",
    "for df in (train_df, val_df, test_df):\n",
    "    df['doc_text'] = df['doc_text'].fillna('').astype(str)\n",
    "\n",
    "# Target\n",
    "y_train = train_df['big_move'].astype(int).values\n",
    "y_val   = val_df['big_move'].astype(int).values\n",
    "y_test  = test_df['big_move'].astype(int).values\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1. TF–IDF features on doc_text\n",
    "# ---------------------------------------------------\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=10000,   # cap vocab size so it doesn't blow up\n",
    "    min_df=5,             # ignore ultra-rare words\n",
    "    max_df=0.7,           # ignore overly common words\n",
    "    ngram_range=(1, 2),   # unigrams + bigrams\n",
    ")\n",
    "\n",
    "X_train_text = tfidf.fit_transform(train_df['doc_text'])\n",
    "X_val_text   = tfidf.transform(val_df['doc_text'])\n",
    "X_test_text  = tfidf.transform(test_df['doc_text'])\n",
    "\n",
    "print(\"TF–IDF shapes:\",\n",
    "      X_train_text.shape, X_val_text.shape, X_test_text.shape)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Helper: evaluate a classifier\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def eval_classifier(clf_name, y_true, y_prob, thr=0.5):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_prob)\n",
    "    except ValueError:\n",
    "        auc = np.nan\n",
    "    print(f\"{clf_name}:\")\n",
    "    print(f\"  Accuracy : {acc:.4f}\")\n",
    "    print(f\"  F1       : {f1:.4f}\")\n",
    "    print(f\"  Precision: {prec:.4f}\")\n",
    "    print(f\"  Recall   : {rec:.4f}\")\n",
    "    print(f\"  AUC      : {auc:.4f}\")\n",
    "    print()\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2. Text-only logistic regression\n",
    "# ---------------------------------------------------\n",
    "\n",
    "logit_text = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=1.0,\n",
    "    class_weight='balanced',\n",
    "    max_iter=1000,\n",
    "    solver='lbfgs'\n",
    ")\n",
    "\n",
    "logit_text.fit(X_train_text, y_train)\n",
    "\n",
    "val_probs_text  = logit_text.predict_proba(X_val_text)[:, 1]\n",
    "test_probs_text = logit_text.predict_proba(X_test_text)[:, 1]\n",
    "\n",
    "print(\"\\n======================\")\n",
    "print(\"TEXT-ONLY LOGISTIC\")\n",
    "print(\"======================\\n\")\n",
    "print(\"Validation performance:\")\n",
    "eval_classifier(\"VAL (text-only)\", y_val, val_probs_text)\n",
    "\n",
    "print(\"Test performance:\")\n",
    "eval_classifier(\"TEST (text-only)\", y_test, test_probs_text)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3. Text + numeric logistic regression\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# Numeric feature set (same as your combined baseline)\n",
    "num_cols = [\n",
    "    'return',\n",
    "    'log_volume',\n",
    "    'mention_count',\n",
    "    'score_sum',\n",
    "    'score_mean',\n",
    "    'post_fraction',\n",
    "    'unique_authors',\n",
    "]\n",
    "\n",
    "# Make sure these exist & no NaNs\n",
    "for c in num_cols:\n",
    "    if c not in train_df.columns:\n",
    "        raise ValueError(f\"Numeric feature '{c}' missing from train_df\")\n",
    "    train_df[c] = train_df[c].fillna(0)\n",
    "    val_df[c]   = val_df[c].fillna(0)\n",
    "    test_df[c]  = test_df[c].fillna(0)\n",
    "\n",
    "X_train_num = train_df[num_cols].values\n",
    "X_val_num   = val_df[num_cols].values\n",
    "X_test_num  = test_df[num_cols].values\n",
    "\n",
    "# Scale numeric part\n",
    "scaler = StandardScaler()\n",
    "X_train_num_scaled = scaler.fit_transform(X_train_num)\n",
    "X_val_num_scaled   = scaler.transform(X_val_num)\n",
    "X_test_num_scaled  = scaler.transform(X_test_num)\n",
    "\n",
    "# Convert numeric to sparse and hstack with TF–IDF\n",
    "X_train_full = hstack([X_train_text, csr_matrix(X_train_num_scaled)])\n",
    "X_val_full   = hstack([X_val_text,   csr_matrix(X_val_num_scaled)])\n",
    "X_test_full  = hstack([X_test_text,  csr_matrix(X_test_num_scaled)])\n",
    "\n",
    "print(\"Combined feature shapes:\",\n",
    "      X_train_full.shape, X_val_full.shape, X_test_full.shape)\n",
    "\n",
    "logit_full = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=1.0,\n",
    "    class_weight='balanced',\n",
    "    max_iter=1000,\n",
    "    solver='lbfgs'\n",
    ")\n",
    "\n",
    "logit_full.fit(X_train_full, y_train)\n",
    "\n",
    "val_probs_full  = logit_full.predict_proba(X_val_full)[:, 1]\n",
    "test_probs_full = logit_full.predict_proba(X_test_full)[:, 1]\n",
    "\n",
    "print(\"\\n======================\")\n",
    "print(\"TEXT + NUMERIC LOGISTIC\")\n",
    "print(\"======================\\n\")\n",
    "print(\"Validation performance:\")\n",
    "eval_classifier(\"VAL (text+num)\", y_val, val_probs_full)\n",
    "\n",
    "print(\"Test performance:\")\n",
    "eval_classifier(\"TEST (text+num)\", y_test, test_probs_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4970f760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter search...\n",
      "Trying TFIDF={'max_features': 5000, 'ngram_range': (1, 1), 'min_df': 5, 'max_df': 0.7}, LOGREG={'C': 0.1, 'class_weight': 'balanced'} ...\n",
      "VAL\n",
      "  Accuracy : 0.7524\n",
      "  F1       : 0.3557\n",
      "  Precision: 0.2622\n",
      "  Recall   : 0.5529\n",
      "  AUC      : 0.7545\n",
      "\n",
      "Trying TFIDF={'max_features': 5000, 'ngram_range': (1, 1), 'min_df': 5, 'max_df': 0.7}, LOGREG={'C': 1.0, 'class_weight': 'balanced'} ...\n",
      "VAL\n",
      "  Accuracy : 0.7607\n",
      "  F1       : 0.3599\n",
      "  Precision: 0.2689\n",
      "  Recall   : 0.5441\n",
      "  AUC      : 0.7567\n",
      "\n",
      "Trying TFIDF={'max_features': 5000, 'ngram_range': (1, 1), 'min_df': 5, 'max_df': 0.7}, LOGREG={'C': 10.0, 'class_weight': 'balanced'} ...\n",
      "VAL\n",
      "  Accuracy : 0.7789\n",
      "  F1       : 0.3289\n",
      "  Precision: 0.2633\n",
      "  Recall   : 0.4382\n",
      "  AUC      : 0.7278\n",
      "\n",
      "Trying TFIDF={'max_features': 5000, 'ngram_range': (1, 1), 'min_df': 5, 'max_df': 0.7}, LOGREG={'C': 1.0, 'class_weight': None} ...\n",
      "VAL\n",
      "  Accuracy : 0.8716\n",
      "  F1       : 0.1810\n",
      "  Precision: 0.4286\n",
      "  Recall   : 0.1147\n",
      "  AUC      : 0.7585\n",
      "\n",
      "Trying TFIDF={'max_features': 10000, 'ngram_range': (1, 1), 'min_df': 5, 'max_df': 0.7}, LOGREG={'C': 0.1, 'class_weight': 'balanced'} ...\n",
      "VAL\n",
      "  Accuracy : 0.7564\n",
      "  F1       : 0.3570\n",
      "  Precision: 0.2650\n",
      "  Recall   : 0.5471\n",
      "  AUC      : 0.7540\n",
      "\n",
      "Trying TFIDF={'max_features': 10000, 'ngram_range': (1, 1), 'min_df': 5, 'max_df': 0.7}, LOGREG={'C': 1.0, 'class_weight': 'balanced'} ...\n",
      "VAL\n",
      "  Accuracy : 0.7735\n",
      "  F1       : 0.3662\n",
      "  Precision: 0.2799\n",
      "  Recall   : 0.5294\n",
      "  AUC      : 0.7577\n",
      "\n",
      "Trying TFIDF={'max_features': 10000, 'ngram_range': (1, 1), 'min_df': 5, 'max_df': 0.7}, LOGREG={'C': 10.0, 'class_weight': 'balanced'} ...\n",
      "VAL\n",
      "  Accuracy : 0.8000\n",
      "  F1       : 0.3514\n",
      "  Precision: 0.2933\n",
      "  Recall   : 0.4382\n",
      "  AUC      : 0.7346\n",
      "\n",
      "Trying TFIDF={'max_features': 10000, 'ngram_range': (1, 1), 'min_df': 5, 'max_df': 0.7}, LOGREG={'C': 1.0, 'class_weight': None} ...\n",
      "VAL\n",
      "  Accuracy : 0.8724\n",
      "  F1       : 0.1780\n",
      "  Precision: 0.4368\n",
      "  Recall   : 0.1118\n",
      "  AUC      : 0.7591\n",
      "\n",
      "Trying TFIDF={'max_features': 10000, 'ngram_range': (1, 2), 'min_df': 5, 'max_df': 0.7}, LOGREG={'C': 0.1, 'class_weight': 'balanced'} ...\n",
      "VAL\n",
      "  Accuracy : 0.7618\n",
      "  F1       : 0.3496\n",
      "  Precision: 0.2639\n",
      "  Recall   : 0.5176\n",
      "  AUC      : 0.7516\n",
      "\n",
      "Trying TFIDF={'max_features': 10000, 'ngram_range': (1, 2), 'min_df': 5, 'max_df': 0.7}, LOGREG={'C': 1.0, 'class_weight': 'balanced'} ...\n",
      "VAL\n",
      "  Accuracy : 0.7822\n",
      "  F1       : 0.3621\n",
      "  Precision: 0.2838\n",
      "  Recall   : 0.5000\n",
      "  AUC      : 0.7602\n",
      "\n",
      "Trying TFIDF={'max_features': 10000, 'ngram_range': (1, 2), 'min_df': 5, 'max_df': 0.7}, LOGREG={'C': 10.0, 'class_weight': 'balanced'} ...\n",
      "VAL\n",
      "  Accuracy : 0.8109\n",
      "  F1       : 0.3333\n",
      "  Precision: 0.2955\n",
      "  Recall   : 0.3824\n",
      "  AUC      : 0.7360\n",
      "\n",
      "Trying TFIDF={'max_features': 10000, 'ngram_range': (1, 2), 'min_df': 5, 'max_df': 0.7}, LOGREG={'C': 1.0, 'class_weight': None} ...\n",
      "VAL\n",
      "  Accuracy : 0.8713\n",
      "  F1       : 0.1531\n",
      "  Precision: 0.4103\n",
      "  Recall   : 0.0941\n",
      "  AUC      : 0.7609\n",
      "\n",
      "Trying TFIDF={'max_features': 20000, 'ngram_range': (1, 2), 'min_df': 5, 'max_df': 0.7}, LOGREG={'C': 0.1, 'class_weight': 'balanced'} ...\n",
      "VAL\n",
      "  Accuracy : 0.7680\n",
      "  F1       : 0.3529\n",
      "  Precision: 0.2693\n",
      "  Recall   : 0.5118\n",
      "  AUC      : 0.7483\n",
      "\n",
      "Trying TFIDF={'max_features': 20000, 'ngram_range': (1, 2), 'min_df': 5, 'max_df': 0.7}, LOGREG={'C': 1.0, 'class_weight': 'balanced'} ...\n",
      "VAL\n",
      "  Accuracy : 0.7945\n",
      "  F1       : 0.3701\n",
      "  Precision: 0.2980\n",
      "  Recall   : 0.4882\n",
      "  AUC      : 0.7620\n",
      "\n",
      "Trying TFIDF={'max_features': 20000, 'ngram_range': (1, 2), 'min_df': 5, 'max_df': 0.7}, LOGREG={'C': 10.0, 'class_weight': 'balanced'} ...\n",
      "VAL\n",
      "  Accuracy : 0.8298\n",
      "  F1       : 0.3536\n",
      "  Precision: 0.3333\n",
      "  Recall   : 0.3765\n",
      "  AUC      : 0.7448\n",
      "\n",
      "Trying TFIDF={'max_features': 20000, 'ngram_range': (1, 2), 'min_df': 5, 'max_df': 0.7}, LOGREG={'C': 1.0, 'class_weight': None} ...\n",
      "VAL\n",
      "  Accuracy : 0.8724\n",
      "  F1       : 0.1460\n",
      "  Precision: 0.4225\n",
      "  Recall   : 0.0882\n",
      "  AUC      : 0.7609\n",
      "\n",
      "\n",
      "Top 5 configs by VAL F1:\n",
      "TFIDF={'max_features': 20000, 'ngram_range': (1, 2), 'min_df': 5, 'max_df': 0.7}, LOGREG={'C': 1.0, 'class_weight': 'balanced'}, F1=0.3701, Prec=0.2980, Rec=0.4882, AUC=0.7620\n",
      "TFIDF={'max_features': 10000, 'ngram_range': (1, 1), 'min_df': 5, 'max_df': 0.7}, LOGREG={'C': 1.0, 'class_weight': 'balanced'}, F1=0.3662, Prec=0.2799, Rec=0.5294, AUC=0.7577\n",
      "TFIDF={'max_features': 10000, 'ngram_range': (1, 2), 'min_df': 5, 'max_df': 0.7}, LOGREG={'C': 1.0, 'class_weight': 'balanced'}, F1=0.3621, Prec=0.2838, Rec=0.5000, AUC=0.7602\n",
      "TFIDF={'max_features': 5000, 'ngram_range': (1, 1), 'min_df': 5, 'max_df': 0.7}, LOGREG={'C': 1.0, 'class_weight': 'balanced'}, F1=0.3599, Prec=0.2689, Rec=0.5441, AUC=0.7567\n",
      "TFIDF={'max_features': 10000, 'ngram_range': (1, 1), 'min_df': 5, 'max_df': 0.7}, LOGREG={'C': 0.1, 'class_weight': 'balanced'}, F1=0.3570, Prec=0.2650, Rec=0.5471, AUC=0.7540\n",
      "\n",
      "Best config (by VAL F1):\n",
      "TFIDF params: {'max_features': 20000, 'ngram_range': (1, 2), 'min_df': 5, 'max_df': 0.7}\n",
      "LOGREG params: {'C': 1.0, 'class_weight': 'balanced'}\n",
      "VAL metrics: {'acc': 0.7945454545454546, 'f1': 0.3701226309921962, 'prec': 0.2980251346499102, 'rec': 0.48823529411764705, 'auc': 0.7620197705638271}\n",
      "\n",
      "=== BEST MODEL ON TEST ===\n",
      "TEST (best tuned model)\n",
      "  Accuracy : 0.7603\n",
      "  F1       : 0.4187\n",
      "  Precision: 0.3209\n",
      "  Recall   : 0.6022\n",
      "  AUC      : 0.7891\n",
      "\n",
      "\n",
      "Best threshold on VAL by F1: 0.50\n",
      "thr=0.10  F1=0.256  Prec=0.147  Rec=0.991\n",
      "thr=0.15  F1=0.283  Prec=0.166  Rec=0.956\n",
      "thr=0.20  F1=0.306  Prec=0.185  Rec=0.888\n",
      "thr=0.25  F1=0.333  Prec=0.207  Rec=0.841\n",
      "thr=0.30  F1=0.339  Prec=0.219  Rec=0.747\n",
      "thr=0.35  F1=0.352  Prec=0.238  Rec=0.674\n",
      "thr=0.40  F1=0.361  Prec=0.257  Rec=0.609\n",
      "thr=0.45  F1=0.368  Prec=0.278  Rec=0.547\n",
      "thr=0.50  F1=0.370  Prec=0.298  Rec=0.488\n",
      "thr=0.55  F1=0.366  Prec=0.322  Rec=0.424\n",
      "thr=0.60  F1=0.354  Prec=0.342  Rec=0.368\n",
      "thr=0.65  F1=0.313  Prec=0.336  Rec=0.294\n",
      "thr=0.70  F1=0.292  Prec=0.356  Rec=0.247\n",
      "thr=0.75  F1=0.289  Prec=0.392  Rec=0.229\n",
      "thr=0.80  F1=0.239  Prec=0.368  Rec=0.176\n",
      "thr=0.85  F1=0.215  Prec=0.397  Rec=0.147\n",
      "thr=0.90  F1=0.173  Prec=0.420  Rec=0.109\n",
      "\n",
      "TEST with tuned threshold=0.50:\n",
      "  Accuracy : 0.7603\n",
      "  F1       : 0.4187\n",
      "  Precision: 0.3209\n",
      "  Recall   : 0.6022\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score\n",
    ")\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 0. Basic setup: targets, numeric features, text\n",
    "# ---------------------------------------------------\n",
    "for df_name, df in [('train_df', train_df), ('val_df', val_df), ('test_df', test_df)]:\n",
    "    if 'doc_text' not in df.columns:\n",
    "        raise ValueError(f\"{df_name} missing 'doc_text'\")\n",
    "    df['doc_text'] = df['doc_text'].fillna('').astype(str)\n",
    "\n",
    "y_train = train_df['big_move'].astype(int).values\n",
    "y_val   = val_df['big_move'].astype(int).values\n",
    "y_test  = test_df['big_move'].astype(int).values\n",
    "\n",
    "num_cols = [\n",
    "    'return',\n",
    "    'log_volume',\n",
    "    'mention_count',\n",
    "    'score_sum',\n",
    "    'score_mean',\n",
    "    'post_fraction',\n",
    "    'unique_authors',\n",
    "]\n",
    "\n",
    "for c in num_cols:\n",
    "    if c not in train_df.columns:\n",
    "        raise ValueError(f\"Numeric feature '{c}' missing from train_df\")\n",
    "    train_df[c] = train_df[c].fillna(0)\n",
    "    val_df[c]   = val_df[c].fillna(0)\n",
    "    test_df[c]  = test_df[c].fillna(0)\n",
    "\n",
    "X_train_num = train_df[num_cols].values\n",
    "X_val_num   = val_df[num_cols].values\n",
    "X_test_num  = test_df[num_cols].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_num_scaled = scaler.fit_transform(X_train_num)\n",
    "X_val_num_scaled   = scaler.transform(X_val_num)\n",
    "X_test_num_scaled  = scaler.transform(X_test_num)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1. Helper: evaluate metrics at threshold=0.5\n",
    "# ---------------------------------------------------\n",
    "def eval_metrics(y_true, y_prob, desc=\"\"):\n",
    "    thr = 0.5\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_prob)\n",
    "    except ValueError:\n",
    "        auc = np.nan\n",
    "    print(desc)\n",
    "    print(f\"  Accuracy : {acc:.4f}\")\n",
    "    print(f\"  F1       : {f1:.4f}\")\n",
    "    print(f\"  Precision: {prec:.4f}\")\n",
    "    print(f\"  Recall   : {rec:.4f}\")\n",
    "    print(f\"  AUC      : {auc:.4f}\")\n",
    "    print()\n",
    "    return {\n",
    "        'acc': acc, 'f1': f1, 'prec': prec, 'rec': rec, 'auc': auc\n",
    "    }\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2. Hyperparameter grids\n",
    "# ---------------------------------------------------\n",
    "\n",
    "tfidf_grid = [\n",
    "    {'max_features': 5000,  'ngram_range': (1, 1), 'min_df': 5, 'max_df': 0.7},\n",
    "    {'max_features': 10000, 'ngram_range': (1, 1), 'min_df': 5, 'max_df': 0.7},\n",
    "    {'max_features': 10000, 'ngram_range': (1, 2), 'min_df': 5, 'max_df': 0.7},\n",
    "    {'max_features': 20000, 'ngram_range': (1, 2), 'min_df': 5, 'max_df': 0.7},\n",
    "]\n",
    "\n",
    "logreg_grid = [\n",
    "    {'C': 0.1, 'class_weight': 'balanced'},\n",
    "    {'C': 1.0, 'class_weight': 'balanced'},\n",
    "    {'C': 10.0, 'class_weight': 'balanced'},\n",
    "    {'C': 1.0, 'class_weight': None},\n",
    "]\n",
    "\n",
    "print(\"Starting hyperparameter search...\")\n",
    "\n",
    "results = []\n",
    "best_model_artifacts = None  # store best vectorizer + model\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3. Manual search over (tfidf_params x logreg_params)\n",
    "# ---------------------------------------------------\n",
    "for tfidf_params in tfidf_grid:\n",
    "    # Build and fit vectorizer on TRAIN ONLY\n",
    "    tfidf = TfidfVectorizer(\n",
    "        max_features=tfidf_params['max_features'],\n",
    "        min_df=tfidf_params['min_df'],\n",
    "        max_df=tfidf_params['max_df'],\n",
    "        ngram_range=tfidf_params['ngram_range']\n",
    "    )\n",
    "    X_train_text = tfidf.fit_transform(train_df['doc_text'])\n",
    "    X_val_text   = tfidf.transform(val_df['doc_text'])\n",
    "\n",
    "    # Combine text + numeric\n",
    "    X_train_full = hstack([X_train_text, csr_matrix(X_train_num_scaled)])\n",
    "    X_val_full   = hstack([X_val_text,   csr_matrix(X_val_num_scaled)])\n",
    "\n",
    "    for log_params in logreg_grid:\n",
    "        print(f\"Trying TFIDF={tfidf_params}, LOGREG={log_params} ...\")\n",
    "\n",
    "        clf = LogisticRegression(\n",
    "            penalty='l2',\n",
    "            C=log_params['C'],\n",
    "            class_weight=log_params['class_weight'],\n",
    "            max_iter=1000,\n",
    "            solver='lbfgs'\n",
    "        )\n",
    "        clf.fit(X_train_full, y_train)\n",
    "\n",
    "        val_probs = clf.predict_proba(X_val_full)[:, 1]\n",
    "        metrics = eval_metrics(y_val, val_probs, desc=\"VAL\")\n",
    "\n",
    "        results.append({\n",
    "            'tfidf': tfidf_params,\n",
    "            'logreg': log_params,\n",
    "            'metrics': metrics\n",
    "        })\n",
    "\n",
    "        # Track best by F1 on validation\n",
    "        if (best_model_artifacts is None) or (metrics['f1'] > best_model_artifacts['metrics']['f1']):\n",
    "            best_model_artifacts = {\n",
    "                'tfidf': tfidf,\n",
    "                'tfidf_params': tfidf_params,\n",
    "                'logreg': clf,\n",
    "                'logreg_params': log_params,\n",
    "                'metrics': metrics\n",
    "            }\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4. Show top configs by F1 on validation\n",
    "# ---------------------------------------------------\n",
    "results_sorted = sorted(results, key=lambda r: r['metrics']['f1'], reverse=True)\n",
    "print(\"\\nTop 5 configs by VAL F1:\")\n",
    "for r in results_sorted[:5]:\n",
    "    m = r['metrics']\n",
    "    print(f\"TFIDF={r['tfidf']}, LOGREG={r['logreg']}, \"\n",
    "          f\"F1={m['f1']:.4f}, Prec={m['prec']:.4f}, Rec={m['rec']:.4f}, AUC={m['auc']:.4f}\")\n",
    "\n",
    "print(\"\\nBest config (by VAL F1):\")\n",
    "print(\"TFIDF params:\", best_model_artifacts['tfidf_params'])\n",
    "print(\"LOGREG params:\", best_model_artifacts['logreg_params'])\n",
    "print(\"VAL metrics:\", best_model_artifacts['metrics'])\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 5. Evaluate best config on TEST\n",
    "#    (Rebuild features for test with best tfidf and same scaler)\n",
    "# ---------------------------------------------------\n",
    "best_tfidf = best_model_artifacts['tfidf']\n",
    "best_clf   = best_model_artifacts['logreg']\n",
    "\n",
    "X_test_text = best_tfidf.transform(test_df['doc_text'])\n",
    "X_test_full = hstack([X_test_text, csr_matrix(X_test_num_scaled)])\n",
    "\n",
    "test_probs = best_clf.predict_proba(X_test_full)[:, 1]\n",
    "print(\"\\n=== BEST MODEL ON TEST ===\")\n",
    "test_metrics = eval_metrics(y_test, test_probs, desc=\"TEST (best tuned model)\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 6. OPTIONAL: Threshold tuning on validation for best model\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def find_best_threshold(y_true, y_prob, metric='f1'):\n",
    "    thresholds = np.linspace(0.1, 0.9, 17)  # 0.1, 0.15, ..., 0.9\n",
    "    best_thr = 0.5\n",
    "    best_val = -1\n",
    "    records = []\n",
    "    for thr in thresholds:\n",
    "        y_pred = (y_prob >= thr).astype(int)\n",
    "        f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "        prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "        rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "        records.append((thr, f1, prec, rec))\n",
    "        if metric == 'f1':\n",
    "            val = f1\n",
    "        elif metric == 'recall':\n",
    "            val = rec\n",
    "        else:\n",
    "            val = f1\n",
    "        if val > best_val:\n",
    "            best_val = val\n",
    "            best_thr = thr\n",
    "    return best_thr, records\n",
    "\n",
    "# Get validation probs for best model\n",
    "X_val_text_best = best_tfidf.transform(val_df['doc_text'])\n",
    "X_val_full_best = hstack([X_val_text_best, csr_matrix(X_val_num_scaled)])\n",
    "val_probs_best  = best_clf.predict_proba(X_val_full_best)[:, 1]\n",
    "\n",
    "best_thr, thr_records = find_best_threshold(y_val, val_probs_best, metric='f1')\n",
    "print(f\"\\nBest threshold on VAL by F1: {best_thr:.2f}\")\n",
    "for thr, f1v, precv, recv in thr_records:\n",
    "    print(f\"thr={thr:.2f}  F1={f1v:.3f}  Prec={precv:.3f}  Rec={recv:.3f}\")\n",
    "\n",
    "# Evaluate tuned threshold on TEST\n",
    "y_test_pred_tuned = (test_probs >= best_thr).astype(int)\n",
    "acc_t = accuracy_score(y_test, y_test_pred_tuned)\n",
    "f1_t  = f1_score(y_test, y_test_pred_tuned, zero_division=0)\n",
    "prec_t= precision_score(y_test, y_test_pred_tuned, zero_division=0)\n",
    "rec_t = recall_score(y_test, y_test_pred_tuned, zero_division=0)\n",
    "print(f\"\\nTEST with tuned threshold={best_thr:.2f}:\")\n",
    "print(f\"  Accuracy : {acc_t:.4f}\")\n",
    "print(f\"  F1       : {f1_t:.4f}\")\n",
    "print(f\"  Precision: {prec_t:.4f}\")\n",
    "print(f\"  Recall   : {rec_t:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ecbd84b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   0.9s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   0.9s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.6s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   2.3s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.7s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   3.0s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   3.3s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   4.0s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   2.7s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   5.9s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   3.9s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   3.8s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   4.6s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.2s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.6s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   5.8s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   9.3s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   2.5s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   3.5s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   3.4s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   4.1s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   0.9s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  12.8s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  10.0s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.8s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   5.8s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   2.7s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  16.4s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   3.5s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  13.1s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   3.9s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   3.4s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.0s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   9.0s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.6s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  15.8s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   2.6s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   5.0s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  12.0s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   3.4s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   3.2s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   4.3s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.1s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   8.4s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.7s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  14.4s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   5.4s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   2.9s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   3.8s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   3.6s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  12.1s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   4.9s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.1s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   9.3s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.5s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   5.6s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  14.1s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   2.5s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  12.6s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   3.4s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   4.0s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   3.3s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.1s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   9.7s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.6s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   5.3s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   2.5s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  15.2s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   3.1s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  12.7s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   3.0s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   3.8s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   8.4s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.0s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.8s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   5.2s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   2.8s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  15.3s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   3.8s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  11.7s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   3.2s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.0s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   4.8s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   8.5s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.9s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  13.9s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   5.3s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   3.0s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  11.8s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   4.2s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   3.4s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.0s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   5.2s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   9.1s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.7s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  14.1s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   5.5s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   2.7s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   3.7s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   3.3s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  12.5s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   9.4s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.1s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   4.7s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.7s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   5.5s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  15.2s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   2.9s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   3.8s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   3.3s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   8.5s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  13.3s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   4.9s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   5.1s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  15.1s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  11.1s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   7.0s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  12.1s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   8.8s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   9.8s\n",
      "Best params: {'clf__C': 1.0, 'clf__class_weight': 'balanced', 'prep__tfidf__max_df': 0.7, 'prep__tfidf__max_features': 10000, 'prep__tfidf__min_df': 5, 'prep__tfidf__ngram_range': (1, 1)}\n",
      "Best CV F1: 0.3623583519471014\n",
      "\n",
      "=== BEST GRID-SEARCH MODEL ON TEST ===\n",
      "Accuracy : 0.7407\n",
      "F1       : 0.4292\n",
      "Precision: 0.3135\n",
      "Recall   : 0.6801\n",
      "AUC      : 0.7868\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 0. Prepare train+val for CV and keep test separate\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# Make sure datetime is sorted\n",
    "train_df = train_df.sort_values('datetime')\n",
    "val_df   = val_df.sort_values('datetime')\n",
    "test_df  = test_df.sort_values('datetime')\n",
    "\n",
    "trainval_df = pd.concat([train_df, val_df], axis=0).sort_values('datetime')\n",
    "\n",
    "# Columns\n",
    "text_col = 'doc_text'\n",
    "num_cols = [\n",
    "    'return',\n",
    "    'log_volume',\n",
    "    'mention_count',\n",
    "    'score_sum',\n",
    "    'score_mean',\n",
    "    'post_fraction',\n",
    "    'unique_authors',\n",
    "]\n",
    "\n",
    "# Fill NaNs\n",
    "trainval_df[text_col] = trainval_df[text_col].fillna('').astype(str)\n",
    "test_df[text_col]     = test_df[text_col].fillna('').astype(str)\n",
    "\n",
    "for c in num_cols:\n",
    "    trainval_df[c] = trainval_df[c].fillna(0)\n",
    "    test_df[c]     = test_df[c].fillna(0)\n",
    "\n",
    "X_trainval = trainval_df[[text_col] + num_cols]\n",
    "y_trainval = trainval_df['big_move'].astype(int).values\n",
    "\n",
    "X_test = test_df[[text_col] + num_cols]\n",
    "y_test = test_df['big_move'].astype(int).values\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1. Build preprocessing + model pipeline\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# ColumnTransformer: apply TF-IDF to text, StandardScaler to numeric\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('tfidf', TfidfVectorizer(), text_col),\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('prep', preprocess),\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2. Define TimeSeriesSplit and hyperparameter grid\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# TimeSeriesSplit: respects chronological order\n",
    "tss = TimeSeriesSplit(\n",
    "    n_splits=5  # 5 folds across time on train+val\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    # TF-IDF hyperparams\n",
    "    'prep__tfidf__max_features': [5000, 10000],\n",
    "    'prep__tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'prep__tfidf__min_df': [5],\n",
    "    'prep__tfidf__max_df': [0.7],\n",
    "\n",
    "    # Logistic hyperparams\n",
    "    'clf__C': [0.1, 1.0, 10.0],\n",
    "    'clf__class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "# We care about F1 for the imbalanced classification\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=tss,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,           # parallelize if you want\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3. Run GridSearchCV on train+val\n",
    "# ---------------------------------------------------\n",
    "\n",
    "grid.fit(X_trainval, y_trainval)\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV F1:\", grid.best_score_)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4. Evaluate best model on TEST\n",
    "# ---------------------------------------------------\n",
    "\n",
    "y_prob_test = best_model.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = (y_prob_test >= 0.5).astype(int)\n",
    "\n",
    "acc  = accuracy_score(y_test, y_pred_test)\n",
    "f1   = f1_score(y_test, y_pred_test, zero_division=0)\n",
    "prec = precision_score(y_test, y_pred_test, zero_division=0)\n",
    "rec  = recall_score(y_test, y_pred_test, zero_division=0)\n",
    "auc  = roc_auc_score(y_test, y_prob_test)\n",
    "\n",
    "print(\"\\n=== BEST GRID-SEARCH MODEL ON TEST ===\")\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"F1       : {f1:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall   : {rec:.4f}\")\n",
    "print(f\"AUC      : {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8e359b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment agg shape: (25176, 7)\n",
      "  ticker   datetime  sent_mean  sent_std  sent_pos_frac  sent_neg_frac  \\\n",
      "0   AAPL 2023-06-09   0.463929  0.402814       0.428571       0.000000   \n",
      "1   AAPL 2023-06-10   0.736300  0.000000       1.000000       0.000000   \n",
      "2   AAPL 2023-06-11   0.826025  0.159468       1.000000       0.000000   \n",
      "3   AAPL 2023-06-12   0.091839  0.501180       0.277778       0.222222   \n",
      "4   AAPL 2023-06-13  -0.035823  0.360812       0.076923       0.076923   \n",
      "\n",
      "   comment_count  \n",
      "0              7  \n",
      "1              1  \n",
      "2              4  \n",
      "3             18  \n",
      "4             13  \n"
     ]
    }
   ],
   "source": [
    "# sentiment analysis \n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "text_col_raw = 'clean_text'  # change to 'body' or whatever your comment column is\n",
    "# ----------------------------\n",
    "\n",
    "# Work on a copy to be safe\n",
    "wsb = wsb_exploded.copy()\n",
    "\n",
    "# Ensure text column is string, no NaNs\n",
    "wsb[text_col_raw] = wsb[text_col_raw].fillna(\"\").astype(str)\n",
    "\n",
    "# 1) Per-comment compound score\n",
    "def _compound(text: str) -> float:\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        return 0.0\n",
    "    return sia.polarity_scores(text)['compound']\n",
    "\n",
    "wsb['sent_compound'] = wsb[text_col_raw].apply(_compound)\n",
    "\n",
    "# 2) Positive / negative flags\n",
    "POS_THR = 0.5\n",
    "NEG_THR = -0.5\n",
    "\n",
    "wsb['is_pos'] = (wsb['sent_compound'] >= POS_THR).astype(int)\n",
    "wsb['is_neg'] = (wsb['sent_compound'] <= NEG_THR).astype(int)\n",
    "\n",
    "# 3) Aggregate to (ticker, datetime)\n",
    "sent_agg = (\n",
    "    wsb\n",
    "    .groupby(['ticker', 'datetime'])\n",
    "    .agg(\n",
    "        sent_mean     = ('sent_compound', 'mean'),\n",
    "        sent_std      = ('sent_compound', 'std'),\n",
    "        sent_pos_frac = ('is_pos', 'mean'),   # fraction of comments that are positive\n",
    "        sent_neg_frac = ('is_neg', 'mean'),   # fraction that are negative\n",
    "        comment_count = ('sent_compound', 'size')  # optional, just for sanity\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# std can be NaN when there is only 1 comment for that (ticker, datetime)\n",
    "sent_agg['sent_std'] = sent_agg['sent_std'].fillna(0.0)\n",
    "\n",
    "print(\"Sentiment agg shape:\", sent_agg.shape)\n",
    "print(sent_agg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "80cc1990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train with sentiment: (12395, 19)\n",
      "Val with sentiment: (2750, 19)\n",
      "Test with sentiment: (2595, 19)\n"
     ]
    }
   ],
   "source": [
    "def merge_sentiment(df, sent_df):\n",
    "    df = df.merge(sent_df, on=['ticker', 'datetime'], how='left')\n",
    "    \n",
    "    # Fill missing sentiment values (days with no comments) with 0\n",
    "    for col in ['sent_mean', 'sent_std', 'sent_pos_frac', 'sent_neg_frac']:\n",
    "        df[col] = df[col].fillna(0.0)\n",
    "    return df\n",
    "\n",
    "train_df = merge_sentiment(train_df, sent_agg)\n",
    "val_df   = merge_sentiment(val_df, sent_agg)\n",
    "test_df  = merge_sentiment(test_df, sent_agg)\n",
    "\n",
    "print(\"Train with sentiment:\", train_df.shape)\n",
    "print(\"Val with sentiment:\",   val_df.shape)\n",
    "print(\"Test with sentiment:\",  test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "722feda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.4s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   0.9s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   2.3s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.6s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   2.9s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   3.2s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   3.7s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   2.4s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   3.1s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   4.9s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   2.9s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   0.9s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   3.7s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.4s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   4.9s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   2.3s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   8.0s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   2.9s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   3.0s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   3.5s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   0.9s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  11.0s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   8.1s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.4s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   4.9s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   2.4s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  13.6s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   2.8s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   2.9s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   3.4s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  11.4s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.0s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   7.7s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.5s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  13.8s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   4.8s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   2.5s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  10.6s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   3.3s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   3.0s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   4.1s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.0s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   8.0s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.7s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  12.9s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   4.9s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   2.6s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   3.5s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  10.6s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   3.1s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   4.4s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   0.9s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   8.3s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.4s\n",
      "[CV] END clf__C=0.1, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  13.1s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   5.3s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   2.4s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   3.1s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   3.0s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  11.7s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   3.9s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.0s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   8.4s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.6s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   4.7s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  13.8s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   2.4s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   3.1s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   3.0s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  12.0s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   4.0s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   8.3s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.2s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.7s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   5.2s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   3.0s\n",
      "[CV] END clf__C=1.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  14.8s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  11.4s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   4.1s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   3.2s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   8.5s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.1s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   5.2s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.9s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   5.2s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  13.5s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   3.1s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  11.5s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   3.5s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   4.4s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.1s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   5.6s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   9.1s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.7s\n",
      "[CV] END clf__C=1.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  14.4s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   5.8s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   2.9s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   3.2s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   3.8s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  12.4s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   9.2s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   4.5s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   1.1s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   5.2s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   2.0s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  15.3s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   2.9s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   4.1s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   3.4s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   8.7s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 1); total time=   5.0s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  13.4s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   5.1s\n",
      "[CV] END clf__C=10.0, clf__class_weight=balanced, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  15.5s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  11.0s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   7.2s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=5000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  12.3s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=   9.2s\n",
      "[CV] END clf__C=10.0, clf__class_weight=None, prep__tfidf__max_df=0.7, prep__tfidf__max_features=10000, prep__tfidf__min_df=5, prep__tfidf__ngram_range=(1, 2); total time=  10.1s\n",
      "Best params: {'clf__C': 1.0, 'clf__class_weight': 'balanced', 'prep__tfidf__max_df': 0.7, 'prep__tfidf__max_features': 10000, 'prep__tfidf__min_df': 5, 'prep__tfidf__ngram_range': (1, 1)}\n",
      "Best CV F1: 0.3628686082013751\n",
      "\n",
      "=== BEST GRID-SEARCH MODEL + SENTIMENT ON TEST ===\n",
      "Accuracy : 0.7407\n",
      "F1       : 0.4282\n",
      "Precision: 0.3130\n",
      "Recall   : 0.6774\n",
      "AUC      : 0.7872\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------------------------------------------\n",
    "# 0. Prepare train+val for CV and keep test separate\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# Make sure datetime is sorted\n",
    "train_df = train_df.sort_values('datetime')\n",
    "val_df   = val_df.sort_values('datetime')\n",
    "test_df  = test_df.sort_values('datetime')\n",
    "\n",
    "trainval_df = pd.concat([train_df, val_df], axis=0).sort_values('datetime')\n",
    "\n",
    "# Columns\n",
    "text_col = 'doc_text'  # this stays the same\n",
    "num_cols = [\n",
    "    'return',\n",
    "    'log_volume',\n",
    "    'mention_count',\n",
    "    'score_sum',\n",
    "    'score_mean',\n",
    "    'post_fraction',\n",
    "    'unique_authors',\n",
    "    'sent_mean',\n",
    "    'sent_std',\n",
    "    'sent_pos_frac',\n",
    "    'sent_neg_frac',\n",
    "]\n",
    "\n",
    "# Fill NaNs\n",
    "trainval_df[text_col] = trainval_df[text_col].fillna('').astype(str)\n",
    "test_df[text_col]     = test_df[text_col].fillna('').astype(str)\n",
    "\n",
    "for c in num_cols:\n",
    "    trainval_df[c] = trainval_df[c].fillna(0)\n",
    "    test_df[c]     = test_df[c].fillna(0)\n",
    "\n",
    "X_trainval = trainval_df[[text_col] + num_cols]\n",
    "y_trainval = trainval_df['big_move'].astype(int).values\n",
    "\n",
    "X_test = test_df[[text_col] + num_cols]\n",
    "y_test = test_df['big_move'].astype(int).values\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1. Build preprocessing + model pipeline\n",
    "# ---------------------------------------------------\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('tfidf', TfidfVectorizer(), text_col),  # WSB text\n",
    "        ('num', StandardScaler(), num_cols),     # price + WSB numeric + sentiment\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('prep', preprocess),\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2. TimeSeriesSplit + hyperparameter grid\n",
    "# ---------------------------------------------------\n",
    "\n",
    "tss = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "param_grid = {\n",
    "    'prep__tfidf__max_features': [5000, 10000],\n",
    "    'prep__tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'prep__tfidf__min_df': [5],\n",
    "    'prep__tfidf__max_df': [0.7],\n",
    "\n",
    "    'clf__C': [0.1, 1.0, 10.0],\n",
    "    'clf__class_weight': ['balanced', None],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=tss,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3. Run GridSearchCV on train+val\n",
    "# ---------------------------------------------------\n",
    "\n",
    "grid.fit(X_trainval, y_trainval)\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV F1:\", grid.best_score_)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4. Evaluate best model on TEST\n",
    "# ---------------------------------------------------\n",
    "\n",
    "y_prob_test = best_model.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = (y_prob_test >= 0.5).astype(int)\n",
    "\n",
    "acc  = accuracy_score(y_test, y_pred_test)\n",
    "f1   = f1_score(y_test, y_pred_test, zero_division=0)\n",
    "prec = precision_score(y_test, y_pred_test, zero_division=0)\n",
    "rec  = recall_score(y_test, y_pred_test, zero_division=0)\n",
    "auc  = roc_auc_score(y_test, y_prob_test)\n",
    "\n",
    "print(\"\\n=== BEST GRID-SEARCH MODEL + SENTIMENT ON TEST ===\")\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"F1       : {f1:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall   : {rec:.4f}\")\n",
    "print(f\"AUC      : {auc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ca3ae4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current split boundaries:\n",
      "  TRAIN:  2023-06-08 00:00:00 → 2024-07-08 00:00:00\n",
      "  VAL:    2024-07-09 00:00:00 → 2024-11-27 00:00:00\n",
      "  TEST:   2024-11-29 00:00:00 → 2025-03-31 00:00:00\n",
      "\n",
      "New price/volume features added: ['ret_prev_1d', 'ret_prev_3d', 'ret_prev_5d', 'vol_5d', 'vol_10d', 'vol_rel_5d', 'log_vol_rel_5d']\n",
      "\n",
      "Shapes after adding features:\n",
      "  train_df: (12395, 26)\n",
      "  val_df:   (2750, 26)\n",
      "  test_df:  (2595, 26)\n"
     ]
    }
   ],
   "source": [
    "# add new numeric stock features\n",
    "# Keep a copy of the split boundaries (datetimes)\n",
    "train_end = train_df['datetime'].max()\n",
    "val_start = val_df['datetime'].min()\n",
    "val_end   = val_df['datetime'].max()\n",
    "test_start = test_df['datetime'].min()\n",
    "test_end   = test_df['datetime'].max()\n",
    "\n",
    "print(\"Current split boundaries:\")\n",
    "print(\"  TRAIN: \", train_df['datetime'].min(), \"→\", train_end)\n",
    "print(\"  VAL:   \", val_start, \"→\", val_end)\n",
    "print(\"  TEST:  \", test_start, \"→\", test_end)\n",
    "\n",
    "full_df = pd.concat([train_df, val_df, test_df], axis=0)\n",
    "full_df = full_df.sort_values(['ticker', 'datetime']).reset_index(drop=True)\n",
    "\n",
    "# If you only have log_volume, reconstruct volume for feature engineering\n",
    "if 'volume' not in full_df.columns:\n",
    "    if 'log_volume' in full_df.columns:\n",
    "        full_df['volume'] = np.expm1(full_df['log_volume'])\n",
    "    else:\n",
    "        raise ValueError(\"Need either 'volume' or 'log_volume' to build volume features.\")\n",
    "\n",
    "# Make sure return has no crazy NaNs\n",
    "full_df['return'] = full_df['return'].fillna(0.0)\n",
    "\n",
    "# --------------------------------------\n",
    "# 1. Compute multi-day returns per ticker\n",
    "# --------------------------------------\n",
    "g = full_df.groupby('ticker', group_keys=False)\n",
    "\n",
    "# Previous-day return\n",
    "full_df['ret_prev_1d'] = g['return'].shift(1)\n",
    "\n",
    "# Last 3 days cumulative (using shifted returns so only past days)\n",
    "full_df['ret_prev_3d'] = g['return'].shift(1).rolling(window=3, min_periods=1).sum()\n",
    "\n",
    "# Last 5 days cumulative\n",
    "full_df['ret_prev_5d'] = g['return'].shift(1).rolling(window=5, min_periods=1).sum()\n",
    "\n",
    "# --------------------------------------\n",
    "# 2. Rolling volatility of returns\n",
    "# --------------------------------------\n",
    "ret_shifted = g['return'].shift(1)\n",
    "\n",
    "full_df['vol_5d'] = ret_shifted.rolling(window=5, min_periods=2).std()\n",
    "full_df['vol_10d'] = ret_shifted.rolling(window=10, min_periods=2).std()\n",
    "\n",
    "# --------------------------------------\n",
    "# 3. Volume anomaly features\n",
    "# --------------------------------------\n",
    "vol_shifted_mean_5d = g['volume'].shift(1).rolling(window=5, min_periods=1).mean()\n",
    "full_df['vol_rel_5d'] = full_df['volume'] / vol_shifted_mean_5d\n",
    "\n",
    "full_df['log_vol_rel_5d'] = np.log1p(full_df['vol_rel_5d'])\n",
    "\n",
    "# --------------------------------------\n",
    "# 4. Clean up / clip outliers / fill NaNs\n",
    "# --------------------------------------\n",
    "new_price_feats = [\n",
    "    'ret_prev_1d',\n",
    "    'ret_prev_3d',\n",
    "    'ret_prev_5d',\n",
    "    'vol_5d',\n",
    "    'vol_10d',\n",
    "    'vol_rel_5d',\n",
    "    'log_vol_rel_5d'\n",
    "]\n",
    "\n",
    "for c in new_price_feats:\n",
    "    # if all NaNs for some ticker early dates, set to 0\n",
    "    full_df[c] = full_df[c].fillna(0.0)\n",
    "    # light winsorization to avoid absurd tail values\n",
    "    lo = full_df[c].quantile(0.01)\n",
    "    hi = full_df[c].quantile(0.99)\n",
    "    full_df[c] = full_df[c].clip(lo, hi)\n",
    "\n",
    "print(\"\\nNew price/volume features added:\", new_price_feats)\n",
    "\n",
    "# --------------------------------------\n",
    "# 5. Re-split full_df back into train / val / test\n",
    "# --------------------------------------\n",
    "train_df = full_df[full_df['datetime'] <= train_end].copy()\n",
    "val_df   = full_df[(full_df['datetime'] > train_end) & (full_df['datetime'] <= val_end)].copy()\n",
    "test_df  = full_df[full_df['datetime'] > val_end].copy()\n",
    "\n",
    "print(\"\\nShapes after adding features:\")\n",
    "print(\"  train_df:\", train_df.shape)\n",
    "print(\"  val_df:  \", val_df.shape)\n",
    "print(\"  test_df: \", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "189750d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "  X_train: (12395, 19)  y_train: (12395,)\n",
      "  X_val:   (2750, 19)  y_val:   (2750,)\n",
      "  X_test:  (2595, 19)  y_test:  (2595,)\n",
      "\n",
      "VAL threshold sweep:\n",
      "thr=0.10  F1=0.272  Prec=0.158  Rec=0.991\n",
      "thr=0.15  F1=0.299  Prec=0.177  Rec=0.953\n",
      "thr=0.20  F1=0.319  Prec=0.194  Rec=0.903\n",
      "thr=0.25  F1=0.335  Prec=0.208  Rec=0.859\n",
      "thr=0.30  F1=0.345  Prec=0.221  Rec=0.788\n",
      "thr=0.35  F1=0.346  Prec=0.229  Rec=0.709\n",
      "thr=0.40  F1=0.348  Prec=0.239  Rec=0.638\n",
      "thr=0.45  F1=0.352  Prec=0.253  Rec=0.576\n",
      "thr=0.50  F1=0.360  Prec=0.271  Rec=0.535\n",
      "thr=0.55  F1=0.349  Prec=0.279  Rec=0.468\n",
      "thr=0.60  F1=0.341  Prec=0.292  Rec=0.412\n",
      "thr=0.65  F1=0.331  Prec=0.305  Rec=0.362\n",
      "thr=0.70  F1=0.318  Prec=0.324  Rec=0.312\n",
      "thr=0.75  F1=0.297  Prec=0.349  Rec=0.259\n",
      "thr=0.80  F1=0.273  Prec=0.383  Rec=0.212\n",
      "thr=0.85  F1=0.223  Prec=0.393  Rec=0.156\n",
      "thr=0.90  F1=0.184  Prec=0.459  Rec=0.115\n",
      "\n",
      "Best VAL threshold by F1: 0.50, F1=0.360, AUC=0.7657\n",
      "\n",
      "=== FIXED-BEST PARAM MODEL (with sentiment + new price features) ON TEST ===\n",
      "Threshold: 0.50\n",
      "Accuracy : 0.7484\n",
      "F1       : 0.4433\n",
      "Precision: 0.3246\n",
      "Recall   : 0.6989\n",
      "AUC      : 0.8041\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1. Prepare data (sorted, define cols)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# Ensure sorted by datetime\n",
    "train_df = train_df.sort_values('datetime')\n",
    "val_df   = val_df.sort_values('datetime')\n",
    "test_df  = test_df.sort_values('datetime')\n",
    "\n",
    "text_col = 'doc_text'\n",
    "\n",
    "base_num_cols = [\n",
    "    'return',\n",
    "    'log_volume',\n",
    "    'mention_count',\n",
    "    'score_sum',\n",
    "    'score_mean',\n",
    "    'post_fraction',\n",
    "    'unique_authors',\n",
    "]\n",
    "\n",
    "sentiment_cols = [\n",
    "    'sent_mean',\n",
    "    'sent_pos_frac',\n",
    "    'sent_neg_frac',\n",
    "    'sent_std',\n",
    "]\n",
    "\n",
    "extra_price_cols = [\n",
    "    'ret_prev_1d',\n",
    "    'ret_prev_3d',\n",
    "    'ret_prev_5d',\n",
    "    'vol_5d',\n",
    "    'vol_10d',\n",
    "    'vol_rel_5d',\n",
    "    'log_vol_rel_5d'\n",
    "]\n",
    "\n",
    "num_cols = base_num_cols + sentiment_cols + extra_price_cols\n",
    "\n",
    "# Fill NaNs\n",
    "for df in [train_df, val_df, test_df]:\n",
    "    df[text_col] = df[text_col].fillna('').astype(str)\n",
    "    for c in num_cols:\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(f\"Missing numeric column in df: {c}\")\n",
    "        df[c] = df[c].fillna(0.0)\n",
    "\n",
    "X_train = train_df[[text_col] + num_cols]\n",
    "y_train = train_df['big_move'].astype(int).values\n",
    "\n",
    "X_val   = val_df[[text_col] + num_cols]\n",
    "y_val   = val_df['big_move'].astype(int).values\n",
    "\n",
    "X_test  = test_df[[text_col] + num_cols]\n",
    "y_test  = test_df['big_move'].astype(int).values\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"  X_train:\", X_train.shape, \" y_train:\", y_train.shape)\n",
    "print(\"  X_val:  \", X_val.shape,   \" y_val:  \", y_val.shape)\n",
    "print(\"  X_test: \", X_test.shape,  \" y_test: \", y_test.shape)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2. Build pipeline with BEST hyperparams (fixed)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('tfidf', TfidfVectorizer(\n",
    "            max_features=10000,\n",
    "            ngram_range=(1, 1),\n",
    "            min_df=5,\n",
    "            max_df=0.7\n",
    "        ), text_col),\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "best_pipe_fixed = Pipeline([\n",
    "    ('prep', preprocess),\n",
    "    ('clf', LogisticRegression(\n",
    "        C=1.0,\n",
    "        class_weight='balanced',\n",
    "        max_iter=1000\n",
    "    ))\n",
    "])\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3. Fit on TRAIN only\n",
    "# ---------------------------------------------------\n",
    "\n",
    "best_pipe_fixed.fit(X_train, y_train)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4. Evaluate on VAL (for threshold tuning)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "y_val_prob = best_pipe_fixed.predict_proba(X_val)[:, 1]\n",
    "\n",
    "def eval_at_threshold(y_true, y_prob, thr):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    return acc, f1, prec, rec\n",
    "\n",
    "# Sweep thresholds to find best F1 on VAL\n",
    "thr_list = np.arange(0.1, 0.91, 0.05)\n",
    "best_thr = 0.5\n",
    "best_f1_val = -1\n",
    "\n",
    "print(\"\\nVAL threshold sweep:\")\n",
    "for thr in thr_list:\n",
    "    acc, f1_, prec, rec = eval_at_threshold(y_val, y_val_prob, thr)\n",
    "    print(f\"thr={thr:0.2f}  F1={f1_:0.3f}  Prec={prec:0.3f}  Rec={rec:0.3f}\")\n",
    "    if f1_ > best_f1_val:\n",
    "        best_f1_val = f1_\n",
    "        best_thr = thr\n",
    "\n",
    "val_auc = roc_auc_score(y_val, y_val_prob)\n",
    "print(f\"\\nBest VAL threshold by F1: {best_thr:0.2f}, F1={best_f1_val:0.3f}, AUC={val_auc:0.4f}\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 5. Final evaluation on TEST using that threshold\n",
    "# ---------------------------------------------------\n",
    "\n",
    "y_test_prob = best_pipe_fixed.predict_proba(X_test)[:, 1]\n",
    "y_test_pred = (y_test_prob >= best_thr).astype(int)\n",
    "\n",
    "test_acc  = accuracy_score(y_test, y_test_pred)\n",
    "test_f1   = f1_score(y_test, y_test_pred, zero_division=0)\n",
    "test_prec = precision_score(y_test, y_test_pred, zero_division=0)\n",
    "test_rec  = recall_score(y_test, y_test_pred, zero_division=0)\n",
    "test_auc  = roc_auc_score(y_test, y_test_prob)\n",
    "\n",
    "print(\"\\n=== FIXED-BEST PARAM MODEL (with sentiment + new price features) ON TEST ===\")\n",
    "print(f\"Threshold: {best_thr:0.2f}\")\n",
    "print(f\"Accuracy : {test_acc:.4f}\")\n",
    "print(f\"F1       : {test_f1:.4f}\")\n",
    "print(f\"Precision: {test_prec:.4f}\")\n",
    "print(f\"Recall   : {test_rec:.4f}\")\n",
    "print(f\"AUC      : {test_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aad83b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New temporal Reddit cols added: ['mention_prev_1d', 'mention_prev_2d', 'sent_mean_prev_1d', 'sent_mean_prev_2d', 'mention_roll3_mean', 'mention_roll3_max', 'sent_mean_roll3', 'mention_prev3_mean', 'buzz_shock_3d']\n",
      "Train shape: (12395, 35)\n",
      "Val shape:   (2750, 35)\n",
      "Test shape:  (2595, 35)\n"
     ]
    }
   ],
   "source": [
    "# reddit temporal features\n",
    "\n",
    "full_df = pd.concat([\n",
    "    train_df.assign(split='train'),\n",
    "    val_df.assign(split='val'),\n",
    "    test_df.assign(split='test'),\n",
    "], ignore_index=True)\n",
    "\n",
    "full_df = full_df.sort_values(['ticker', 'datetime'])\n",
    "\n",
    "# Sanity checks\n",
    "assert 'ticker' in full_df.columns, \"Need ticker column\"\n",
    "assert 'mention_count' in full_df.columns, \"Need mention_count\"\n",
    "assert 'sent_mean' in full_df.columns, \"Need sent_mean\"\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2. Temporal Reddit features by ticker\n",
    "# ---------------------------------------------------\n",
    "g = full_df.groupby('ticker', group_keys=False)\n",
    "\n",
    "# Lags: t-1, t-2 (mentions + sentiment)\n",
    "full_df['mention_prev_1d']   = g['mention_count'].shift(1)\n",
    "full_df['mention_prev_2d']   = g['mention_count'].shift(2)\n",
    "full_df['sent_mean_prev_1d'] = g['sent_mean'].shift(1)\n",
    "full_df['sent_mean_prev_2d'] = g['sent_mean'].shift(2)\n",
    "\n",
    "# 3-day rolling stats (inclusive of current day t)\n",
    "roll3_ment_mean = g['mention_count'].rolling(3, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "roll3_ment_max  = g['mention_count'].rolling(3, min_periods=1).max().reset_index(level=0, drop=True)\n",
    "roll3_sent_mean = g['sent_mean'].rolling(3, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "full_df['mention_roll3_mean'] = roll3_ment_mean\n",
    "full_df['mention_roll3_max']  = roll3_ment_max\n",
    "full_df['sent_mean_roll3']    = roll3_sent_mean\n",
    "\n",
    "# Previous 3-day average mentions (t-1, t-2, t-3) for buzz shock\n",
    "prev3_mean = (\n",
    "    g['mention_count']\n",
    "    .shift(1)                                # exclude today\n",
    "    .rolling(3, min_periods=1)\n",
    "    .mean()\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "full_df['mention_prev3_mean'] = prev3_mean\n",
    "full_df['buzz_shock_3d'] = full_df['mention_count'] / (prev3_mean + 1e-6)\n",
    "\n",
    "reddit_temp_cols = [\n",
    "    'mention_prev_1d', 'mention_prev_2d',\n",
    "    'sent_mean_prev_1d', 'sent_mean_prev_2d',\n",
    "    'mention_roll3_mean', 'mention_roll3_max',\n",
    "    'sent_mean_roll3',\n",
    "    'mention_prev3_mean',\n",
    "    'buzz_shock_3d'\n",
    "]\n",
    "\n",
    "# Fill NaNs from early days with 0 (you could also drop those rows if you prefer)\n",
    "full_df[reddit_temp_cols] = full_df[reddit_temp_cols].fillna(0.0)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3. Split back to train / val / test\n",
    "# ---------------------------------------------------\n",
    "train_df = full_df[full_df['split'] == 'train'].drop(columns=['split']).copy()\n",
    "val_df   = full_df[full_df['split'] == 'val'].drop(columns=['split']).copy()\n",
    "test_df  = full_df[full_df['split'] == 'test'].drop(columns=['split']).copy()\n",
    "\n",
    "print(\"New temporal Reddit cols added:\", reddit_temp_cols)\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Val shape:  \", val_df.shape)\n",
    "print(\"Test shape: \", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "880074f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (12395, 28)  y_train: (12395,)\n",
      "X_val:   (2750, 28)  y_val:   (2750,)\n",
      "X_test:  (2595, 28)  y_test:  (2595,)\n",
      "\n",
      "VAL threshold sweep (with temporal Reddit features):\n",
      "thr=0.10  F1=0.271  Prec=0.157  Rec=0.988\n",
      "thr=0.15  F1=0.300  Prec=0.178  Rec=0.953\n",
      "thr=0.20  F1=0.318  Prec=0.193  Rec=0.900\n",
      "thr=0.25  F1=0.333  Prec=0.207  Rec=0.841\n",
      "thr=0.30  F1=0.344  Prec=0.221  Rec=0.782\n",
      "thr=0.35  F1=0.346  Prec=0.229  Rec=0.706\n",
      "thr=0.40  F1=0.348  Prec=0.240  Rec=0.635\n",
      "thr=0.45  F1=0.350  Prec=0.252  Rec=0.576\n",
      "thr=0.50  F1=0.354  Prec=0.267  Rec=0.526\n",
      "thr=0.55  F1=0.352  Prec=0.282  Rec=0.468\n",
      "thr=0.60  F1=0.339  Prec=0.290  Rec=0.409\n",
      "thr=0.65  F1=0.332  Prec=0.307  Rec=0.362\n",
      "thr=0.70  F1=0.320  Prec=0.326  Rec=0.315\n",
      "thr=0.75  F1=0.311  Prec=0.367  Rec=0.271\n",
      "thr=0.80  F1=0.286  Prec=0.398  Rec=0.224\n",
      "thr=0.85  F1=0.225  Prec=0.402  Rec=0.156\n",
      "thr=0.90  F1=0.207  Prec=0.474  Rec=0.132\n",
      "\n",
      "Best VAL threshold: 0.50, F1=0.354, AUC=0.7657\n",
      "\n",
      "=== BEST FIXED LOGISTIC + TF-IDF + PRICE + TEMPORAL REDDIT ON TEST ===\n",
      "Threshold: 0.50\n",
      "Accuracy : 0.7487\n",
      "F1       : 0.4446\n",
      "Precision: 0.3254\n",
      "Recall   : 0.7016\n",
      "AUC      : 0.8052\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# 1. Define columns (extend num_cols with temporal Reddit)\n",
    "# ---------------------------------------------------\n",
    "text_col = 'doc_text'\n",
    "\n",
    "base_num_cols = [\n",
    "    'return',\n",
    "    'log_volume',\n",
    "    'mention_count',\n",
    "    'score_sum',\n",
    "    'score_mean',\n",
    "    'post_fraction',\n",
    "    'unique_authors',\n",
    "]\n",
    "\n",
    "sentiment_cols = [\n",
    "    'sent_mean',\n",
    "    'sent_pos_frac',\n",
    "    'sent_neg_frac',\n",
    "    'sent_std',\n",
    "]\n",
    "\n",
    "extra_price_cols = [\n",
    "    'ret_prev_1d',\n",
    "    'ret_prev_3d',\n",
    "    'ret_prev_5d',\n",
    "    'vol_5d',\n",
    "    'vol_10d',\n",
    "    'vol_rel_5d',\n",
    "    'log_vol_rel_5d'\n",
    "]\n",
    "\n",
    "reddit_temp_cols = [\n",
    "    'mention_prev_1d', 'mention_prev_2d',\n",
    "    'sent_mean_prev_1d', 'sent_mean_prev_2d',\n",
    "    'mention_roll3_mean', 'mention_roll3_max',\n",
    "    'sent_mean_roll3',\n",
    "    'mention_prev3_mean',\n",
    "    'buzz_shock_3d'\n",
    "]\n",
    "\n",
    "num_cols = base_num_cols + sentiment_cols + extra_price_cols + reddit_temp_cols\n",
    "\n",
    "# Fill NaNs\n",
    "for df in [train_df, val_df, test_df]:\n",
    "    df[text_col] = df[text_col].fillna('').astype(str)\n",
    "    for c in num_cols:\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(f\"Missing numeric column: {c}\")\n",
    "        df[c] = df[c].fillna(0.0)\n",
    "\n",
    "X_train = train_df[[text_col] + num_cols]\n",
    "y_train = train_df['big_move'].astype(int).values\n",
    "\n",
    "X_val   = val_df[[text_col] + num_cols]\n",
    "y_val   = val_df['big_move'].astype(int).values\n",
    "\n",
    "X_test  = test_df[[text_col] + num_cols]\n",
    "y_test  = test_df['big_move'].astype(int).values\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \" y_train:\", y_train.shape)\n",
    "print(\"X_val:  \", X_val.shape,   \" y_val:  \", y_val.shape)\n",
    "print(\"X_test: \", X_test.shape,  \" y_test: \", y_test.shape)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2. Fixed best pipeline (same hyperparams as before)\n",
    "# ---------------------------------------------------\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('tfidf', TfidfVectorizer(\n",
    "            max_features=10000,\n",
    "            ngram_range=(1, 1),\n",
    "            min_df=5,\n",
    "            max_df=0.7\n",
    "        ), text_col),\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('prep', preprocess),\n",
    "    ('clf', LogisticRegression(\n",
    "        C=1.0,\n",
    "        class_weight='balanced',\n",
    "        max_iter=1000\n",
    "    ))\n",
    "])\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3. Fit on TRAIN\n",
    "# ---------------------------------------------------\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4. Threshold tuning on VAL by F1\n",
    "# ---------------------------------------------------\n",
    "import numpy as np\n",
    "\n",
    "y_val_prob = pipe.predict_proba(X_val)[:, 1]\n",
    "\n",
    "def eval_at_thr(y_true, y_prob, thr):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    return (\n",
    "        accuracy_score(y_true, y_pred),\n",
    "        f1_score(y_true, y_pred, zero_division=0),\n",
    "        precision_score(y_true, y_pred, zero_division=0),\n",
    "        recall_score(y_true, y_pred, zero_division=0),\n",
    "    )\n",
    "\n",
    "thr_list = np.arange(0.1, 0.91, 0.05)\n",
    "best_thr = 0.5\n",
    "best_f1  = -1\n",
    "\n",
    "print(\"\\nVAL threshold sweep (with temporal Reddit features):\")\n",
    "for thr in thr_list:\n",
    "    acc, f1_, prec, rec = eval_at_thr(y_val, y_val_prob, thr)\n",
    "    print(f\"thr={thr:0.2f}  F1={f1_:0.3f}  Prec={prec:0.3f}  Rec={rec:0.3f}\")\n",
    "    if f1_ > best_f1:\n",
    "        best_f1 = f1_\n",
    "        best_thr = thr\n",
    "\n",
    "val_auc = roc_auc_score(y_val, y_val_prob)\n",
    "print(f\"\\nBest VAL threshold: {best_thr:0.2f}, F1={best_f1:0.3f}, AUC={val_auc:0.4f}\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 5. Final TEST evaluation\n",
    "# ---------------------------------------------------\n",
    "y_test_prob = pipe.predict_proba(X_test)[:, 1]\n",
    "y_test_pred = (y_test_prob >= best_thr).astype(int)\n",
    "\n",
    "test_acc  = accuracy_score(y_test, y_test_pred)\n",
    "test_f1   = f1_score(y_test, y_test_pred, zero_division=0)\n",
    "test_prec = precision_score(y_test, y_test_pred, zero_division=0)\n",
    "test_rec  = recall_score(y_test, y_test_pred, zero_division=0)\n",
    "test_auc  = roc_auc_score(y_test, y_test_prob)\n",
    "\n",
    "print(\"\\n=== BEST FIXED LOGISTIC + TF-IDF + PRICE + TEMPORAL REDDIT ON TEST ===\")\n",
    "print(f\"Threshold: {best_thr:0.2f}\")\n",
    "print(f\"Accuracy : {test_acc:.4f}\")\n",
    "print(f\"F1       : {test_f1:.4f}\")\n",
    "print(f\"Precision: {test_prec:.4f}\")\n",
    "print(f\"Recall   : {test_rec:.4f}\")\n",
    "print(f\"AUC      : {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245eeb4d",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5a6ef0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
